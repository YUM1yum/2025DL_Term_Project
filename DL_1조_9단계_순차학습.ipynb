{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YUM1yum/2025DL_Term_Project/blob/main/DL_1%EC%A1%B0_9%EB%8B%A8%EA%B3%84_%EC%88%9C%EC%B0%A8%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUeV08P_C5pR",
        "outputId": "fc3a1a41-4c3a-4f2e-eea5-5c06491abbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가상 데이터 생성, 성능 테스트를 위한 데이터 업로드"
      ],
      "metadata": {
        "id": "UYOLL2xXxYzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train_dataset"
      ],
      "metadata": {
        "id": "rMtIsVLQC78O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배경\n",
        "!unzip train_dataset/stage1.zip -d ./train_dataset/\n",
        "!unzip train_dataset/stage2.zip -d ./train_dataset/\n",
        "!unzip train_dataset/stage3.zip -d ./train_dataset/\n",
        "!unzip train_dataset/stage4.zip -d ./train_dataset/\n",
        "!unzip train_dataset/stage3_label.zip -d ./train_dataset/stage3_label\n",
        "!unzip train_dataset/stage4_label.zip -d ./train_dataset/stage4_label\n",
        "\n",
        "# 아이콘\n",
        "!unzip train_dataset/icon_3.zip -d ./train_dataset/icons/\n",
        "\n",
        "# 아덜즈\n",
        "!unzip train_dataset/others.zip -d ./train_dataset/others/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNwtvVh6weeq",
        "outputId": "73e17795-f9d1-49c3-91fd-5c0f09fcd433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train_dataset/stage1.zip\n",
            "  inflating: ./train_dataset/stage1/a1.png  \n",
            "  inflating: ./train_dataset/stage1/a11133.png  \n",
            "  inflating: ./train_dataset/stage1/a2342.png  \n",
            "  inflating: ./train_dataset/stage1/a311.jpg  \n",
            "  inflating: ./train_dataset/stage1/a41.png  \n",
            "  inflating: ./train_dataset/stage1/a4212.png  \n",
            "  inflating: ./train_dataset/stage1/a45.png  \n",
            "  inflating: ./train_dataset/stage1/a5.png  \n",
            "  inflating: ./train_dataset/stage1/a6543.png  \n",
            "  inflating: ./train_dataset/stage1/a7777777777777.png  \n",
            "  inflating: ./train_dataset/stage1/a88.png  \n",
            "  inflating: ./train_dataset/stage1/a942.png  \n",
            "Archive:  train_dataset/stage2.zip\n",
            "  inflating: ./train_dataset/stage2/b1111115.png  \n",
            "  inflating: ./train_dataset/stage2/b1234.png  \n",
            "  inflating: ./train_dataset/stage2/b12413.png  \n",
            "  inflating: ./train_dataset/stage2/b2.png  \n",
            "  inflating: ./train_dataset/stage2/b2134.png  \n",
            "  inflating: ./train_dataset/stage2/b2323.png  \n",
            "  inflating: ./train_dataset/stage2/b3155.png  \n",
            "  inflating: ./train_dataset/stage2/b324.png  \n",
            "  inflating: ./train_dataset/stage2/b3333.png  \n",
            "  inflating: ./train_dataset/stage2/b4.png  \n",
            "  inflating: ./train_dataset/stage2/b4211.png  \n",
            "  inflating: ./train_dataset/stage2/b43243.png  \n",
            "  inflating: ./train_dataset/stage2/b51.png  \n",
            "  inflating: ./train_dataset/stage2/b511.png  \n",
            "  inflating: ./train_dataset/stage2/b512.png  \n",
            "  inflating: ./train_dataset/stage2/b543.png  \n",
            "  inflating: ./train_dataset/stage2/b544444.png  \n",
            "  inflating: ./train_dataset/stage2/b61.png  \n",
            "  inflating: ./train_dataset/stage2/b767.png  \n",
            "Archive:  train_dataset/stage3.zip\n",
            "   creating: ./train_dataset/stage3/\n",
            "  inflating: ./train_dataset/stage3/c13.png  \n",
            "  inflating: ./train_dataset/stage3/c142.png  \n",
            "  inflating: ./train_dataset/stage3/c2131.png  \n",
            "  inflating: ./train_dataset/stage3/c4.png  \n",
            "  inflating: ./train_dataset/stage3/c41.png  \n",
            "  inflating: ./train_dataset/stage3/c434.png  \n",
            "  inflating: ./train_dataset/stage3/c4444.png  \n",
            "  inflating: ./train_dataset/stage3/c5.png  \n",
            "  inflating: ./train_dataset/stage3/c51.png  \n",
            "  inflating: ./train_dataset/stage3/c52.png  \n",
            "  inflating: ./train_dataset/stage3/c522.png  \n",
            "  inflating: ./train_dataset/stage3/c5234.png  \n",
            "  inflating: ./train_dataset/stage3/c542.png  \n",
            "  inflating: ./train_dataset/stage3/c543.png  \n",
            "  inflating: ./train_dataset/stage3/c554.png  \n",
            "  inflating: ./train_dataset/stage3/c6123.png  \n",
            "  inflating: ./train_dataset/stage3/c62.png  \n",
            "  inflating: ./train_dataset/stage3/c66635.png  \n",
            "  inflating: ./train_dataset/stage3/c7111.png  \n",
            "  inflating: ./train_dataset/stage3/c72.png  \n",
            "  inflating: ./train_dataset/stage3/c822.png  \n",
            "  inflating: ./train_dataset/stage3/c8888.png  \n",
            "  inflating: ./train_dataset/stage3/c987.png  \n",
            "Archive:  train_dataset/stage4.zip\n",
            "   creating: ./train_dataset/stage4/\n",
            "  inflating: ./train_dataset/stage4/d123.png  \n",
            "  inflating: ./train_dataset/stage4/d2.png  \n",
            "  inflating: ./train_dataset/stage4/d212.png  \n",
            "  inflating: ./train_dataset/stage4/d2227.png  \n",
            "  inflating: ./train_dataset/stage4/d23.png  \n",
            "  inflating: ./train_dataset/stage4/d31.png  \n",
            "  inflating: ./train_dataset/stage4/d32.png  \n",
            "  inflating: ./train_dataset/stage4/d4.png  \n",
            "  inflating: ./train_dataset/stage4/d43.png  \n",
            "  inflating: ./train_dataset/stage4/d4525.png  \n",
            "  inflating: ./train_dataset/stage4/d5111111.png  \n",
            "  inflating: ./train_dataset/stage4/d512.png  \n",
            "  inflating: ./train_dataset/stage4/d55555553.png  \n",
            "  inflating: ./train_dataset/stage4/d6.png  \n",
            "  inflating: ./train_dataset/stage4/d611114.png  \n",
            "  inflating: ./train_dataset/stage4/d612.png  \n",
            "  inflating: ./train_dataset/stage4/d6122223.png  \n",
            "  inflating: ./train_dataset/stage4/d6222.png  \n",
            "  inflating: ./train_dataset/stage4/d622222.png  \n",
            "  inflating: ./train_dataset/stage4/d6234.png  \n",
            "  inflating: ./train_dataset/stage4/d64.png  \n",
            "  inflating: ./train_dataset/stage4/d642.png  \n",
            "  inflating: ./train_dataset/stage4/d65.png  \n",
            "  inflating: ./train_dataset/stage4/d661.png  \n",
            "  inflating: ./train_dataset/stage4/d6723.png  \n",
            "  inflating: ./train_dataset/stage4/d721.png  \n",
            "  inflating: ./train_dataset/stage4/d7234.png  \n",
            "  inflating: ./train_dataset/stage4/d75312.png  \n",
            "  inflating: ./train_dataset/stage4/d762.png  \n",
            "  inflating: ./train_dataset/stage4/d776 (1).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (10).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (2).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (3).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (4).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (5).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (6).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (7).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (8).png  \n",
            "  inflating: ./train_dataset/stage4/d776 (9).png  \n",
            "  inflating: ./train_dataset/stage4/d777777.png  \n",
            "  inflating: ./train_dataset/stage4/d8234.png  \n",
            "  inflating: ./train_dataset/stage4/d8875.png  \n",
            "  inflating: ./train_dataset/stage4/d9.png  \n",
            "  inflating: ./train_dataset/stage4/d91.png  \n",
            "  inflating: ./train_dataset/stage4/d93.png  \n",
            "  inflating: ./train_dataset/stage4/d94.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211758.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211818.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211839.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211853.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211907.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211923.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211932.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211946.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 211958.png  \n",
            "  inflating: ./train_dataset/stage4/스크린샷 2025-06-21 212123.png  \n",
            "Archive:  train_dataset/stage3_label.zip\n",
            "  inflating: ./train_dataset/stage3_label/c4.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c5.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c13.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c41.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c51.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c52.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c62.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c72.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c142.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c434.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c522.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c542.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c543.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c554.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c822.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c987.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c2131.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c4444.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c5234.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c6123.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c7111.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c8888.txt  \n",
            "  inflating: ./train_dataset/stage3_label/c66635.txt  \n",
            "Archive:  train_dataset/stage4_label.zip\n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211839.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211853.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211907.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211923.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211932.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211946.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211958.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 212123.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d2.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d4.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d6.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d9.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d23.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d31.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d32.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d43.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d64.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d65.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d91.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d93.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d94.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d123.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d212.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d512.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d612.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d642.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d661.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d721.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d762.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (1).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (2).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (3).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (4).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (5).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (6).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (7).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (8).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (9).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d776 (10).txt  \n",
            "  inflating: ./train_dataset/stage4_label/d2227.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d4525.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d6222.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d6234.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d6723.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d7234.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d8234.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d8875.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d75312.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d611114.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d622222.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d777777.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d5111111.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d6122223.txt  \n",
            "  inflating: ./train_dataset/stage4_label/d55555553.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211758.txt  \n",
            "  inflating: ./train_dataset/stage4_label/스크린샷 2025-06-21 211818.txt  \n",
            "Archive:  train_dataset/icon_3.zip\n",
            "   creating: ./train_dataset/icons/black/\n",
            "  inflating: ./train_dataset/icons/black/3p_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/4k_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_alert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_call_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_comment_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_photo_alternate_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_shopping_cart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/add_task_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/ads_click_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/ad_group_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/alarm_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/alarm_pause_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/all_out_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/analytics_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/animation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/approval_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/archive_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_back_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_downward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_drop_down_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_drop_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_insert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_menu_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/arrow_upward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/article_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/assistant_direction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/attach_email_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/attribution_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/auto_delete_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/award_star_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/background_replace_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/barcode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/barcode_scanner_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/battery_0_bar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/bedtime_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/block_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/blur_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/book_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/book_ribbon_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/bottom_navigation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/boy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/bring_your_own_ip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/broken_image_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/browse_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/browse_gallery_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/calendar_month_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/call_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/call_made_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/call_missed_outgoing_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/cancel_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/cast_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/center_focus_strong_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/change_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/change_history_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/chat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/checklist_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/check_box_outline_blank_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/chef_hat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/chips_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/cloud_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/cloud_download_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/construction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/contrast_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/co_present_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/credit_card_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/cycle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/database_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/database_upload_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/dehaze_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/delete_sweep_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/desktop_windows_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/directions_car_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/disabled_by_default_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/domain_verification_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/done_all_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/done_outline_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/downloading_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/download_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/drafts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/drive_folder_upload_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/dynamic_feed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/east_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/edit_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/eject_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/emoji_objects_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/engineering_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/enterprise_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/event_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/event_available_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/event_note_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/event_repeat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/exit_to_app_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/expand_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/expand_circle_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/expand_content_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/file_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/filter_center_focus_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/filter_list_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/filter_none_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/first_page_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/fit_screen_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/folder_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/folder_zip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/forward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-15861077_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-15861089_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-17767660_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-17767669_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-17767701_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914208_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914248_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914337_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914663_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914694_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-add-3914725_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-10513294_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-10513349_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916894_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916912_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916931_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916934_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916954_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-left-3916962_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-10513298_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-10513350_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916889_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916907_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916924_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916925_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916949_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-angle-right-3916959_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-16861338_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-16861349_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-16861361_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-17490081_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-3917226_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-3917235_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-3917237_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-3917240_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-3917270_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-ring-3914279_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-bell-ring-3914535_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-caret-down-10513329_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-caret-down-10513364_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-caret-down-3916922_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-caret-down-3916968_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-check-17767693_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-check-3917008_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-check-3917039_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-cross-17593965_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-cross-3917050_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-cross-3917189_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-cross-3917759_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-envelope-18561374_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-envelope-3916611_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-envelope-3916631_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-home-3917032_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-home-3917033_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-interrogation-18439130_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-interrogation-18996255_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-interrogation-3916709_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-interrogation-3916718_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-17767757_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-17767767_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-17767806_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-3917065_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-3917215_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-3917220_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-3917291_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-menu-burger-3917762_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-search-3917026_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-search-3917127_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-search-3917132_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-search-3917515_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-search-3917754_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-share-3917447_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-share-3917786_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-user-17766671_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-user-3917546_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-user-3917688_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-user-3917705_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/free-icon-font-user-3917796_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/front_hand_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/fullscreen_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/graphic_eq_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/headphones_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/health_cross_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/help_center_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/highlight_mouse_cursor_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/hub_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/image_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/inbox_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/info_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/input_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/ios_share_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/keep_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/keyboard_arrow_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/keyboard_arrow_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/kid_star_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/label_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/label_important_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/last_page_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/library_add_check_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/library_music_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/license_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/lightbulb_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/lightbulb_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/list_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/local_shipping_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/location_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/lock_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/lock_open_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mail_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mail_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/map_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/map_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mark_chat_unread_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mark_email_read_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/memory_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/menu_book_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mic_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/model_training_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/monitoring_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/mood_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/movie_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/near_me_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/new_window_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/next_plan_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/north_east_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/notifications_unread_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/notification_add_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/notification_multiple_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/no_accounts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/outbox_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/pageview_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/palette_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/pan_tool_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/pan_zoom_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/partly_cloudy_night_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/payments_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/pending_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/person_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/person_4_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/person_remove_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/phone_bluetooth_speaker_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/photo_library_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/pin_end_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/place_item_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/playlist_add_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/playlist_add_check_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/play_arrow_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/podcasts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/privacy_tip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/problem_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/qr_code_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/queue_music_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/rainy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/recycling_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/refresh_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/remove_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/remove_shopping_cart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/restart_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/rss_feed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/saved_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/save_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/sdk_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/select_all_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/select_check_box_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/send_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/sentiment_excited_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/settings_accessibility_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/settings_applications_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/share_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/shift_lock_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/shopping_basket_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/shuffle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/signal_disconnected_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/sim_card_download_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/skip_next_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/sort_by_alpha_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/speaker_phone_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/start_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/stat_3_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/stat_minus_1_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/stop_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/stop_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/storefront_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/store_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/subdirectory_arrow_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/subject_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/subway_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/swap_vertical_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/switch_access_shortcut_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/switch_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/symptoms_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/sync_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/system_update_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/tab_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/task_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/terminal_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/text_fields_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/today_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/toggle_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/toggle_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/touch_app_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/tv_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/unarchive_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/unfold_less_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/update_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/upgrade_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/upload_file_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/verified_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/vertical_align_bottom_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/vertical_align_center_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/view_cozy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/view_timeline_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/visibility_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/visibility_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/voicemail_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/volume_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/volume_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/web_asset_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/web_traffic_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/wifi_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/black/wifi_tethering_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "   creating: ./train_dataset/icons/else/\n",
            "  inflating: ./train_dataset/icons/else/attachment.png  \n",
            "  inflating: ./train_dataset/icons/else/audio.png  \n",
            "  inflating: ./train_dataset/icons/else/box_notes.png  \n",
            "  inflating: ./train_dataset/icons/else/eps.png  \n",
            "  inflating: ./train_dataset/icons/else/excel.png  \n",
            "  inflating: ./train_dataset/icons/else/exe.png  \n",
            "  inflating: ./train_dataset/icons/else/flash.png  \n",
            "  inflating: ./train_dataset/icons/else/folder.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-add-148781.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-airbnb-2111320.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-alarm-148920.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-android-174836.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-bank-3845851.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-books-3845824.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-bridge-136553.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-browser-3845849.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-cash-flow-4149652.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-clouds-136701.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-clouds-and-sun-136716.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-communications-10036865.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-communications-5356260.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-communications-6348872.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-communications-7762257.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-contact-info-2545893.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-daily-health-app-3845768.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-diamond-332035.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-diamond-332056.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-diamond-332063.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-diamond-ring-332037.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-discord-2111370.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-dropbox-2111381.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-envelope-171893.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-equal-148783.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-error-148766.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-folder-148953.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-folder-148957.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-folder-3845783.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-gift-332036.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-google-drive-2111436.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-google-play-2111445.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-house-3845763.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-illustrator-136518.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-image-3845723.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-internet-148848.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-like-148836.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-like-2111493.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-linkedin-174857.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-market-analysis-4149657.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-medal-171889.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-medium-174858.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-moon-136756.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-morning-rain-136714.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-mortarboard-3845897.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-movies-app-3845894.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-netflix-732228.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-operation-4149660.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-pages-3845895.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-pause-148746.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-pdf-136522.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-placeholder-148845.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-placeholder-149060.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-play-button-148744.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-plus-148764.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-png-136523.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-podcast-3845814.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-process-4149678.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-productivity-4149648.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-raining-136711.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-report-4149706.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-restaurant-10309202.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-search-148928.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-search-3845863.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-settings-148913 (1).png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-settings-148913.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-settings-171918.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-settings-3845826.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-shortcut-script-app-3845837.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-slack-2111615.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-snapchat-2111616.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-snowflake-136755.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-snowing-136710.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-solution-4149693.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-soundcloud-174871.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-speech-bubble-3845696.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-spotify-174872.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-spotify-3845874.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-spreadsheet-app-3845896.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-star-148839.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-success-148767.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-sunny-136723.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-sunset-136734.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-telephone-3845704.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-tide-136702.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-tiktok-3845867.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-translate-3845839.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-tv-app-3845752.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-twitter-5968830.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-video-editing-app-3845875.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-wallet-passes-app-3845819.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-watch-332054.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-weather-app-3845731.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-wikipedia-174880.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-windows-220215.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-word-888883.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-wordpress-2111731.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-youtube-2111748.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-youtube-3845856.png  \n",
            "  inflating: ./train_dataset/icons/else/free-icon-zip-136544.png  \n",
            "  inflating: ./train_dataset/icons/else/gdoc.png  \n",
            "  inflating: ./train_dataset/icons/else/gform.png  \n",
            "  inflating: ./train_dataset/icons/else/gsheet.png  \n",
            "  inflating: ./train_dataset/icons/else/html.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-adidas-trefoil-64.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-cancel-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-menu-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-picasa-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-x-ы░ХьКд-эБмыбЬьКд-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-ыж╜ьКдэЛ▒-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-ьХДъ╕░-ы│С-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-ьЫР-эФМыаИьЭ┤-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-ьЭД-babys-ыг╕-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-ьЭ┤ы░ЬьВм-ъ░АьЬД-100.png  \n",
            "  inflating: ./train_dataset/icons/else/icons8-эК╕ыаИьЭ┤ыДИ-100.png  \n",
            "  inflating: ./train_dataset/icons/else/image.png  \n",
            "  inflating: ./train_dataset/icons/else/instagram_1384063.png  \n",
            "  inflating: ./train_dataset/icons/else/kakao-talk_3991999.png  \n",
            "  inflating: ./train_dataset/icons/else/library_folder.png  \n",
            "  inflating: ./train_dataset/icons/else/link.png  \n",
            "  inflating: ./train_dataset/icons/else/mp4.png  \n",
            "  inflating: ./train_dataset/icons/else/pack.png  \n",
            "  inflating: ./train_dataset/icons/else/pdf.png  \n",
            "  inflating: ./train_dataset/icons/else/ppt.png  \n",
            "  inflating: ./train_dataset/icons/else/psd.png  \n",
            "  inflating: ./train_dataset/icons/else/quip_slide.png  \n",
            "  inflating: ./train_dataset/icons/else/shared_folder.png  \n",
            "  inflating: ./train_dataset/icons/else/slide.png  \n",
            "  inflating: ./train_dataset/icons/else/txt.png  \n",
            "  inflating: ./train_dataset/icons/else/unknown.png  \n",
            "  inflating: ./train_dataset/icons/else/video.png  \n",
            "  inflating: ./train_dataset/icons/else/visio.png  \n",
            "  inflating: ./train_dataset/icons/else/webex.png  \n",
            "  inflating: ./train_dataset/icons/else/word.png  \n",
            "  inflating: ./train_dataset/icons/else/youtube_3938026.png  \n",
            "  inflating: ./train_dataset/icons/else/zip.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102550.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102602.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102610.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102621.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102631.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102641.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102707.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102730.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 102739.png  \n",
            "  inflating: ./train_dataset/icons/else/ьКдэБмыж░ьГ╖ 2025-06-21 103634.png  \n",
            "   creating: ./train_dataset/icons/white/\n",
            "  inflating: ./train_dataset/icons/white/3p_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/4k_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/account_balance_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/account_balance_wallet_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/account_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_alert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_a_photo_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_call_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_card_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_comment_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_photo_alternate_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_reaction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_shopping_cart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/add_task_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/admin_panel_settings_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/ads_click_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/ad_group_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/alarm_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/alarm_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/alarm_pause_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/all_out_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/analytics_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/animation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/approval_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/apps_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/archive_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrows_output_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_back_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_back_ios_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_circle_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_circle_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_downward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_downward_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_drop_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_drop_down_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_drop_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_forward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_insert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_left_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_menu_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_right_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_selector_tool_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_upward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/arrow_upward_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/article_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/assignment_turned_in_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/assistant_direction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/assistant_navigation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/attachment_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/attach_email_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/attribution_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/auto_awesome_motion_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/auto_delete_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/award_star_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/background_replace_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/backup_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/barcode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/barcode_scanner_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/battery_0_bar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/battery_5_bar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/battery_full_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/battery_low_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bedtime_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/block_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bluetooth_connected_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/blur_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bolt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bookmarks_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bookmark_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bookmark_added_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bookmark_add_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bookmark_star_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/book_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/book_ribbon_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bottom_navigation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/boy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/bring_your_own_ip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/broken_image_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/browse_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/browse_gallery_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/calendar_month_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/calendar_today_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/call_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/call_made_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/call_missed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/call_missed_outgoing_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/call_received_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/campaign_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cancel_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cardiology_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/card_membership_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cast_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/category_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/celebration_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cell_tower_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/center_focus_strong_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/change_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/change_history_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chat_add_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chat_bubble_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chat_info_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/checklist_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/check_box_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/check_box_outline_blank_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/check_small_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chef_hat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chevron_backward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chevron_forward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chips_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/chrome_reader_mode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/clear_all_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/closed_caption_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cloud_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cloud_done_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cloud_download_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/code_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/code_blocks_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/collections_bookmark_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/compare_arrows_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/component_exchange_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/compress_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/construction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/contact_support_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/content_copy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/contrast_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/co_present_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/credit_card_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/credit_score_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/cycle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/dangerous_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/dark_mode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/database_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/database_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/database_upload_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/dataset_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/data_info_alert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/dehaze_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/delete_sweep_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/density_small_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/deployed_code_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/description_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/desktop_windows_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/developer_guide_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/directions_car_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/disabled_by_default_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/diversity_4_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/domain_verification_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/done_all_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/done_outline_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/downloading_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/download_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/download_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/download_done_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/download_for_offline_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/do_not_disturb_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/drafts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/drag_indicator_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/drag_pan_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/drive_folder_upload_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/dynamic_feed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/east_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/editor_choice_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/edit_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/edit_document_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/edit_square_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/eject_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/emergency_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/emoji_objects_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/engineering_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/enhanced_encryption_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/enterprise_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/error_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/event_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/event_available_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/event_list_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/event_note_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/event_repeat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/exclamation_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/exit_to_app_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/expand_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/expand_circle_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/expand_circle_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/expand_circle_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/expand_content_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/fast_forward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/feature_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/feedback_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/file_copy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/file_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/file_present_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/filter_center_focus_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/filter_list_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/filter_none_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/first_page_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/fit_screen_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/flight_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/folder_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/folder_copy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/folder_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/folder_zip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/format_list_bulleted_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/format_size_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/forward_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/front_hand_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/fullscreen_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/fullscreen_exit_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/graphic_eq_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/group_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/g_translate_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/handshake_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/headphones_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/health_cross_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/hearing_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/heart_plus_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/height_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/help_center_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/hide_source_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/highlight_keyboard_focus_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/highlight_mouse_cursor_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/hourglass_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/hourglass_disabled_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/how_to_reg_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/hub_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/identity_platform_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/image_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/import_contacts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/inbox_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/info_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/input_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/inventory_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/inventory_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/invert_colors_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/ios_share_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keep_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keep_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_arrow_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_arrow_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_arrow_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_arrow_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_backspace_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_control_key_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_double_arrow_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_double_arrow_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_double_arrow_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/keyboard_return_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/key_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/kid_star_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/label_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/label_important_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/language_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/last_page_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/library_add_check_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/library_books_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/library_music_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/license_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lightbulb_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lightbulb_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/light_mode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/list_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/local_library_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/local_shipping_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/location_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lock_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lock_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lock_open_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/lock_person_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/loyalty_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mail_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mail_lock_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mail_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/manage_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/manufacturing_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/man_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/map_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/map_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mark_chat_unread_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mark_email_read_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mark_email_unread_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/memory_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/menu_book_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/menu_open_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mic_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/model_training_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/monitoring_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mood_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/more_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/more_horiz_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/more_time_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/mouse_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/movie_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/near_me_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/network_wifi_3_bar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/new_window_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/next_plan_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/north_east_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/notifications_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/notifications_active_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/notifications_unread_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/notification_add_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/notification_multiple_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/no_accounts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/offline_bolt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/offline_pin_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/online_prediction_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/open_in_full_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/open_in_new_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/open_in_new_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/outbox_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/outgoing_mail_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/output_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/output_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pageview_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/palette_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pan_tool_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pan_tool_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pan_zoom_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/partly_cloudy_night_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/payments_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pending_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/perm_contact_calendar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/perm_media_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/person_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/person_4_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/person_pin_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/person_remove_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/person_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/phone_bluetooth_speaker_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/phone_enabled_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/photo_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/photo_camera_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/photo_library_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pill_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pin_drop_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/pin_end_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/place_item_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/playlist_add_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/playlist_add_check_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/play_arrow_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/play_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/podcasts_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/power_settings_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/preview_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/print_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/priority_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/priority_high_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/privacy_tip_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/problem_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/published_with_changes_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/qr_code_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/qr_code_scanner_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/queue_music_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/quiz_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/radio_button_unchecked_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/rainy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/rate_review_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/recommend_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/recycling_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/redo_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/refresh_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/release_alert_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/remove_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/remove_shopping_cart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/repeat_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/repeat_one_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/replay_10_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/replay_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/replay_30_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/reply_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/report_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/resize_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/restart_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/route_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/rss_feed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/saved_search_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/save_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/savings_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/schedule_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/school_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sdk_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/search_check_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/security_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/select_all_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/select_check_box_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/select_window_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sell_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/send_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sentiment_dissatisfied_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sentiment_excited_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sentiment_satisfied_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_accessibility_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_applications_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_bluetooth_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_ethernet_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_overscan_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_phone_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/settings_power_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/share_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shield_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shift_lock_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shoppingmode_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shopping_bag_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shopping_basket_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shopping_cart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shopping_cart_checkout_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/show_chart_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/shuffle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/signal_disconnected_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sim_card_download_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/skip_next_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/skip_previous_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sort_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sort_by_alpha_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/speaker_notes_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/speaker_phone_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/speed_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stacked_email_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stack_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stack_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stars_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/start_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stat_1_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stat_3_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stat_minus_1_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stat_minus_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stop_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/stop_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/storage_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/storefront_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/store_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/subdirectory_arrow_left_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/subdirectory_arrow_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/subject_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/subway_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sunny_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/supervisor_account_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/swap_horizontal_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/swap_horizontal_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/swap_horiz_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/swap_vertical_circle_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/swipe_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/switch_access_shortcut_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/switch_right_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/symptoms_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sync_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/sync_disabled_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/system_update_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/tab_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/tab_inactive_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/target_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/task_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/task_alt_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24 (1)_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/terminal_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/text_fields_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/thumb_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/timer_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/timer_play_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/today_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/toggle_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/toggle_on_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/token_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/topic_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/touch_app_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/touch_double_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/trackpad_input_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/train_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/trending_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/tune_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/tv_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/unarchive_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/undo_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/unfold_less_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/unfold_less_double_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/unfold_more_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/unsubscribe_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/upcoming_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/update_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/upgrade_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/upload_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/upload_file_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/verified_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/verified_user_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vertical_align_bottom_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vertical_align_center_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vertical_align_top_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/videocam_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/videocam_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/video_call_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/video_library_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/view_cozy_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/view_in_ar_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/view_kanban_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/view_timeline_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/visibility_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/visibility_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vital_signs_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/voicemail_2_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/voice_over_off_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/volume_down_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/volume_up_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/volunteer_activism_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vpn_lock_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/vrpano_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/web_asset_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/web_traffic_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/width_full_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/wifi_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/wifi_tethering_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/workspaces_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "  inflating: ./train_dataset/icons/white/zoom_in_24dp_E3E3E3_FILL0_wght400_GRAD0_opsz24_64px.png  \n",
            "Archive:  train_dataset/others.zip\n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141815.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141823.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141831.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141851.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141859.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141904.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141914.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141921.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141930.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 141955.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142007.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142102.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142112.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142117.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142123.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142153.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142200.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142206.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142215.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142219.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142226.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142253.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142312.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142316.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142321.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142327.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142332.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142342.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142348.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142354.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142400.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142404.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142410.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-20 142413.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 092947.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093002.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093012.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093016.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093027.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093039.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093146.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093151.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093155.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093204.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093209.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093220.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093226.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093236.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093243.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093248.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093326.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093341.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093346.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093429.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093434.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093448.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093458.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093606.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093614.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093708.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093714.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093735.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093812.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093821.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093827.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093855.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093920.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093930.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 093941.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094017.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094053.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094104.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094109.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094119.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094142.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094148.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094202.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094227.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094257.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094302.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094310.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094318.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094326.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094333.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094351.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 094639.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205009.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205013.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205017.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205022.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205031.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205035.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205133.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205146.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205154.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205213.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205219.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205226.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205233.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205308.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205315.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205336.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205346.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205416.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205430.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205436.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205443.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205447.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205641.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205646.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205651.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205655.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205725.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205749.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205758.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205834.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205840.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205851.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205924.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205940.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205947.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205954.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 205958.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210002.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210008.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210012.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210111.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210123.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210136.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210252.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210300.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210322.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210331.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210351.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210359.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210415.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210425.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210520.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210540.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210548.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210603.png  \n",
            "  inflating: ./train_dataset/others/스크린샷 2025-06-21 210613.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/test_data_all.zip\"\n",
        "extract_path = \"/content/test_dataset/test_data\"\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ 압축 해제 완료\")"
      ],
      "metadata": {
        "id": "fYqZ9VGaWSw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50374004-99bb-46c3-970d-e7f58b5fcc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 압축 해제 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1~9단계 가상 데이터 생성\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "IYungafYxSy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1단계"
      ],
      "metadata": {
        "id": "BkU7-mEbxcIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1단계\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 🧮 생성할 이미지 개수\n",
        "num_images = 200\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dir = root / \"stage1\"\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step1\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 유틸 함수\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "# 데이터 로딩\n",
        "bg_list = list(bg_dir.glob(\"*.*\"))\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "# 데이터 생성\n",
        "for idx in range(num_images):\n",
        "    bg = Image.open(random.choice(bg_list)).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 아덜즈 먼저 (크기 스케일↑)\n",
        "    for _ in range(random.randint(5, 9)):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)  # 🎯 키움\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘\n",
        "    for _ in range(random.randint(5, 12)):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        candidates = icons_black if bright else icons_white\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.2, 0.6)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "TgUzmbP7DQYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2단계"
      ],
      "metadata": {
        "id": "jh9mi6o0xfeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 2\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 🧮 생성할 이미지 개수\n",
        "num_images = 300\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dirs = [root / \"stage1\", root / \"stage2\"]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step2\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "bg_list = sum([list(p.glob(\"*.*\")) for p in bg_dirs], [])\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "for idx in range(num_images):\n",
        "    bg = Image.open(random.choice(bg_list)).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 아덜즈 (크기 키움)\n",
        "    for _ in range(random.randint(5, 10)):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 (크기 줄임)\n",
        "    for _ in range(random.randint(3, 15)):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        candidates = icons_black if bright else icons_white\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.3, 0.6)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "ZIiUsHdVIJnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3단계"
      ],
      "metadata": {
        "id": "CjKXVLxgxhbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 3\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 🧮 생성할 이미지 개수\n",
        "num_images = 400\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dirs = [root / \"stage3\", root / \"stage4\"]\n",
        "label_dirs = [root / \"stage3_label\", root / \"stage4_label\"]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step3\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "bg_list = []\n",
        "bg_to_label = {}\n",
        "\n",
        "for bg_dir, lbl_dir in zip(bg_dirs, label_dirs):\n",
        "    for bg_path in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_path)\n",
        "        label_path = lbl_dir / (bg_path.stem + \".txt\")\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as f:\n",
        "                bg_to_label[bg_path.name] = f.read().strip()\n",
        "        else:\n",
        "            bg_to_label[bg_path.name] = \"\"\n",
        "\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and icons_color and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "for idx in range(num_images):\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 배경 라벨 붙이기\n",
        "    existing_labels = bg_to_label.get(bg_path.name, \"\")\n",
        "    if existing_labels:\n",
        "        label_lines.extend(existing_labels.splitlines())\n",
        "\n",
        "    # 아덜즈 (7~12)\n",
        "    for _ in range(random.randint(7, 12)):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 (7~15), 흑백+컬러 포함\n",
        "    for _ in range(random.randint(7, 15)):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        use_color = random.random() < 0.3\n",
        "        if use_color:\n",
        "            candidates = icons_color\n",
        "        else:\n",
        "            candidates = icons_black if bright else icons_white\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.3, 0.8)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "VIBodf4FM24F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4단계"
      ],
      "metadata": {
        "id": "Zt_NZVl_xj4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 4\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageFilter\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 🧮 생성할 이미지 개수\n",
        "num_images = 500\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dirs = [root / \"stage3\"]\n",
        "label_dirs = [root / \"stage3_label\"]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step4\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "# 배경 이미지와 해당 라벨 불러오기\n",
        "bg_list = []\n",
        "bg_to_label = {}\n",
        "for bg_dir, lbl_dir in zip(bg_dirs, label_dirs):\n",
        "    for bg_path in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_path)\n",
        "        label_path = lbl_dir / (bg_path.stem + \".txt\")\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as f:\n",
        "                bg_to_label[bg_path.name] = f.read().strip()\n",
        "        else:\n",
        "            bg_to_label[bg_path.name] = \"\"\n",
        "\n",
        "# 객체 이미지 불러오기\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and icons_color and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "for idx in range(num_images):\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 기존 배경 라벨 붙이기\n",
        "    existing_labels = bg_to_label.get(bg_path.name, \"\")\n",
        "    if existing_labels:\n",
        "        label_lines.extend(existing_labels.splitlines())\n",
        "\n",
        "    # 아덜즈 (5~15개)\n",
        "    for _ in range(random.randint(5, 15)):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 (10~20개), 컬러 포함, 전체 작게\n",
        "    for _ in range(random.randint(12, 25)):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        use_color = random.random() < 0.3\n",
        "        candidates = icons_color if use_color else (icons_black if bright else icons_white)\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.3, 1.0)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 💥 노이즈 추가\n",
        "    arr = np.array(bg)\n",
        "    noise = np.random.normal(0, 8, arr.shape).astype(np.int16)\n",
        "    noisy_arr = np.clip(arr.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "    bg = Image.fromarray(noisy_arr)\n",
        "\n",
        "    # 저장\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "4-9nkmsiN9At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5단계"
      ],
      "metadata": {
        "id": "z-SyAewFxl-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#####5\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 🧮 생성할 이미지 개수\n",
        "num_images = 500\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dirs = [root / \"stage4\"]\n",
        "label_dirs = [root / \"stage4_label\"]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step5\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "# 배경 이미지와 라벨 불러오기\n",
        "bg_list = []\n",
        "bg_to_label = {}\n",
        "for bg_dir, lbl_dir in zip(bg_dirs, label_dirs):\n",
        "    for bg_path in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_path)\n",
        "        label_path = lbl_dir / (bg_path.stem + \".txt\")\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as f:\n",
        "                bg_to_label[bg_path.name] = f.read().strip()\n",
        "        else:\n",
        "            bg_to_label[bg_path.name] = \"\"\n",
        "\n",
        "# 객체 이미지 불러오기\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and icons_color and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "for idx in range(num_images):\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 기존 배경 라벨 붙이기\n",
        "    existing_labels = bg_to_label.get(bg_path.name, \"\")\n",
        "    if existing_labels:\n",
        "        label_lines.extend(existing_labels.splitlines())\n",
        "\n",
        "    # 아덜즈 (5~15개)\n",
        "    for _ in range(random.randint(5, 15)):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 (7~20개), 흑백+컬러\n",
        "    for _ in range(random.randint(7, 24)):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        use_color = random.random() < 0.3\n",
        "        candidates = icons_color if use_color else (icons_black if bright else icons_white)\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.3, 0.8)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        # 💥 경계 흐림\n",
        "        if random.random() < 0.3:\n",
        "            obj = obj.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 💥 밝기 대비, 색상 교란, 노이즈\n",
        "    enhancer = ImageEnhance.Contrast(bg)\n",
        "    bg = enhancer.enhance(random.uniform(0.9, 1.3))  # 대비 조정\n",
        "    enhancer = ImageEnhance.Color(bg)\n",
        "    bg = enhancer.enhance(random.uniform(0.8, 1.4))  # 색조 조정\n",
        "\n",
        "    arr = np.array(bg)\n",
        "    noise = np.random.normal(0, 6, arr.shape).astype(np.int16)\n",
        "    noisy_arr = np.clip(arr.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "    bg = Image.fromarray(noisy_arr)\n",
        "\n",
        "    # 저장\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "VCqQZqH2OF76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6단계"
      ],
      "metadata": {
        "id": "WrGCtWAmxn74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#####6\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 생성할 이미지 수\n",
        "num_images = 400\n",
        "max_blank_images = int(num_images * 0.10)  # 최대 백지 10%\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_dirs = [root / \"stage4\"]\n",
        "label_dirs = [root / \"stage4_label\"]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step6\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "# 배경 이미지와 라벨 불러오기\n",
        "bg_list = []\n",
        "bg_to_label = {}\n",
        "for bg_dir, lbl_dir in zip(bg_dirs, label_dirs):\n",
        "    for bg_path in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_path)\n",
        "        label_path = lbl_dir / (bg_path.stem + \".txt\")\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as f:\n",
        "                bg_to_label[bg_path.name] = f.read().strip()\n",
        "        else:\n",
        "            bg_to_label[bg_path.name] = \"\"\n",
        "\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and icons_color and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "blank_count = 0\n",
        "for idx in range(num_images):\n",
        "    while True:\n",
        "        icon_count = random.randint(0, 12)\n",
        "        other_count = random.randint(0, 12)\n",
        "        if icon_count == 0 and other_count == 0:\n",
        "            if blank_count < max_blank_images:\n",
        "                blank_count += 1\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 배경 라벨\n",
        "    existing_labels = bg_to_label.get(bg_path.name, \"\")\n",
        "    if existing_labels:\n",
        "        label_lines.extend(existing_labels.splitlines())\n",
        "\n",
        "    # 아덜즈\n",
        "    for _ in range(other_count):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘\n",
        "    for _ in range(icon_count):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        use_color = random.random() < 0.3\n",
        "        candidates = icons_color if use_color else (icons_black if bright else icons_white)\n",
        "        if not candidates: continue\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        scale = random.uniform(0.3, 1.2)\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 저장\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "4BFVTq2YO5TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7단계"
      ],
      "metadata": {
        "id": "h0rN9QFexp65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 7\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# 생성할 이미지 수\n",
        "num_images = 300\n",
        "max_blank_images = int(num_images * 0.10)  # 최대 백지 10%\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_stages = [1, 2, 3, 4]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step7\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "# 배경 이미지 + 라벨 불러오기\n",
        "bg_list = []\n",
        "bg_to_label = {}\n",
        "for s in bg_stages:\n",
        "    bg_dir = root / f\"stage{s}\"\n",
        "    lbl_dir = root / f\"stage{s}_label\"\n",
        "    for bg_path in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_path)\n",
        "        label_path = lbl_dir / (bg_path.stem + \".txt\")\n",
        "        if label_path.exists():\n",
        "            with open(label_path, \"r\") as f:\n",
        "                bg_to_label[bg_path.name] = f.read().strip()\n",
        "        else:\n",
        "            bg_to_label[bg_path.name] = \"\"\n",
        "\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and icons_color and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "blank_count = 0\n",
        "for idx in range(num_images):\n",
        "    while True:\n",
        "        icon_count = random.randint(0, 20)\n",
        "        other_count = random.randint(0, 20)\n",
        "        if icon_count == 0 and other_count == 0:\n",
        "            if blank_count < max_blank_images:\n",
        "                blank_count += 1\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 배경 라벨 붙이기 (있으면)\n",
        "    existing_labels = bg_to_label.get(bg_path.name, \"\")\n",
        "    if existing_labels:\n",
        "        label_lines.extend(existing_labels.splitlines())\n",
        "\n",
        "    # 아덜즈 (0~20)\n",
        "    for _ in range(other_count):\n",
        "        obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 (0~20), 대부분 작게, 가끔 크게\n",
        "    for _ in range(icon_count):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        use_color = random.random() < 0.3\n",
        "        candidates = icons_color if use_color else (icons_black if bright else icons_white)\n",
        "        if not candidates: continue\n",
        "        # 크기 선택: 대부분 작게, 가끔 크게\n",
        "        if random.random() < 0.85:\n",
        "            scale = random.uniform(0.3, 0.8)\n",
        "        else:\n",
        "            scale = random.uniform(1.2, 2.0)\n",
        "        obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x = random.randint(0, img_w - w)\n",
        "        y = random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 저장\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "ibm-2z1KSU-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8단계"
      ],
      "metadata": {
        "id": "kap9U-NHxrwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 8\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "# 생성할 이미지 수\n",
        "num_images = 600\n",
        "max_blank_images = int(num_images * 0.01)  # 최대 백지 1%\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 35\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_stages = [1, 2, 3, 4]\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step8\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 유틸리티 함수들\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "def apply_noise(img_pil):\n",
        "    img = np.array(img_pil)\n",
        "    noise = np.random.normal(0, 25, img.shape).astype(np.uint8)\n",
        "    img = cv2.add(img, noise)\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "# case 확률 분포 정의\n",
        "def choose_case():\n",
        "    rnd = random.random()\n",
        "    if rnd < 0.60:\n",
        "        return 'general'\n",
        "    elif rnd < 0.61:\n",
        "        return 'blank'\n",
        "    else:\n",
        "        pick = random.random()\n",
        "        table = [\n",
        "            ('small_only', 0.10),\n",
        "            ('large_only', 0.10),\n",
        "            ('mixed_scale', 0.06),\n",
        "            ('many_adult_few_icon', 0.05),\n",
        "            ('tiny_few', 0.025),\n",
        "            ('overlap', 0.025),\n",
        "            ('transparent', 0.025),\n",
        "            ('adult_only', 0.01),\n",
        "            ('icon_only', 0.01),\n",
        "            ('same_icon', 0.005),\n",
        "            ('corner_icon', 0.005)\n",
        "        ]\n",
        "        cum = 0\n",
        "        for name, prob in table:\n",
        "            cum += prob\n",
        "            if pick <= cum:\n",
        "                return name\n",
        "        return 'general'\n",
        "\n",
        "# 배경 이미지 및 라벨 사전 구성\n",
        "bg_list = []\n",
        "bg_labels = {}\n",
        "for stage in bg_stages:\n",
        "    bg_dir = root / f\"stage{stage}\"\n",
        "    label_dir = root / f\"stage{stage}_label\"\n",
        "    for bg_file in bg_dir.glob(\"*.*\"):\n",
        "        bg_list.append(bg_file)\n",
        "        label_file = label_dir / (bg_file.stem + \".txt\")\n",
        "        if label_file.exists():\n",
        "            with open(label_file, 'r') as f:\n",
        "                bg_labels[bg_file.name] = f.read().strip()\n",
        "\n",
        "# 생성 루프 시작\n",
        "blank_count = 0\n",
        "for idx in range(num_images):\n",
        "    case = choose_case()\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    # 스테이지 3, 4 라벨 자동 포함\n",
        "    if bg_path.name in bg_labels:\n",
        "        label_lines.append(bg_labels[bg_path.name])\n",
        "\n",
        "    if case == 'blank':\n",
        "        if blank_count < max_blank_images:\n",
        "            blank_count += 1\n",
        "            bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "            with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "                f.write(\"\")\n",
        "            continue\n",
        "        else:\n",
        "            case = 'general'  # 초과 시 일반으로 대체\n",
        "\n",
        "    # 아이콘 & 아덜즈 수 결정\n",
        "    icon_count = random.randint(0, 20)\n",
        "    other_count = random.randint(0, 20)\n",
        "    if case == 'adult_only': icon_count = 0\n",
        "    if case == 'icon_only': other_count = 0\n",
        "    if case == 'many_adult_few_icon': icon_count = random.randint(0, 3); other_count = random.randint(15, 20)\n",
        "    if case == 'tiny_few': icon_count = random.randint(1, 3)\n",
        "\n",
        "    # 아이콘 붙이기\n",
        "    for _ in range(icon_count):\n",
        "        patch_w = patch_h = base_icon_size\n",
        "        x = random.randint(0, img_w - patch_w)\n",
        "        y = random.randint(0, img_h - patch_h)\n",
        "        patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "        bright = is_bright(patch)\n",
        "        candidates = icons_black if bright else icons_white\n",
        "        if not candidates: continue\n",
        "        obj_path = random.choice(candidates)\n",
        "        obj = Image.open(obj_path).convert(\"RGBA\")\n",
        "\n",
        "        if case == 'small_only': scale = random.uniform(0.2, 0.4)\n",
        "        elif case == 'large_only': scale = random.uniform(1.5, 2.5)\n",
        "        elif case == 'mixed_scale': scale = random.uniform(0.2, 2.0)\n",
        "        elif case == 'tiny_few': scale = random.uniform(0.2, 0.3)\n",
        "        else: scale = random.uniform(0.3, 0.8) if random.random() < 0.85 else random.uniform(1.2, 2.0)\n",
        "\n",
        "        obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "\n",
        "        if case == 'corner_icon':\n",
        "            corners = [(0,0), (img_w-w,0), (0,img_h-h), (img_w-w,img_h-h)]\n",
        "            x, y = random.choice(corners)\n",
        "        else:\n",
        "            x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "\n",
        "        if case == 'transparent':\n",
        "            obj_np = np.array(obj)\n",
        "            obj_np[..., 3] = int(255 * 0.5)  # 50% 투명도\n",
        "            obj = Image.fromarray(obj_np)\n",
        "\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아덜즈 붙이기\n",
        "    for _ in range(other_count):\n",
        "        obj_path = random.choice(list(other_dir.glob(\"*.*\")))\n",
        "        obj = Image.open(obj_path).convert(\"RGBA\")\n",
        "        scale = random.uniform(1.0, 1.8)\n",
        "        obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "        w, h = obj.size\n",
        "        if w >= img_w or h >= img_h: continue\n",
        "        x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "        bg.paste(obj, (x, y), obj)\n",
        "        label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 저장\n",
        "    bg = apply_noise(bg)\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "3faaCKmIWQGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9단계"
      ],
      "metadata": {
        "id": "sIZVO_PmxtnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### 9\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "# 생성할 이미지 수\n",
        "num_images = 500\n",
        "max_blank_images = int(num_images * 0.10)  # 최대 백지 10%\n",
        "\n",
        "# 설정\n",
        "base_icon_size = 50\n",
        "base_other_size = 40\n",
        "fixed_bg_size = (1280, 720)\n",
        "brightness_threshold = 127\n",
        "\n",
        "# 경로\n",
        "root = Path(\"/content/train_dataset\")\n",
        "bg_stages = [3, 4]  # 복잡한 배경만 사용\n",
        "icon_black_dir = root / \"icons/black\"\n",
        "icon_white_dir = root / \"icons/white\"\n",
        "icon_color_dir = root / \"icons/else\"\n",
        "other_dir = root / \"others\"\n",
        "step_dir = root / \"step9\"\n",
        "out_img_dir = step_dir / \"images/train\"\n",
        "out_lbl_dir = step_dir / \"labels/train\"\n",
        "out_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 유틸리티 함수들\n",
        "def is_bright(patch):\n",
        "    gray = np.array(patch.convert(\"L\"))\n",
        "    return np.mean(gray) > brightness_threshold\n",
        "\n",
        "def resize_keep_ratio(img, target_long):\n",
        "    w, h = img.size\n",
        "    scale = target_long / max(w, h)\n",
        "    return img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "\n",
        "def resize_with_padding(img, target_size):\n",
        "    img = img.convert(\"RGBA\")\n",
        "    w, h = img.size\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "    canvas = Image.new(\"RGBA\", (target_size, target_size), (0, 0, 0, 0))\n",
        "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2), img)\n",
        "    return canvas\n",
        "\n",
        "def apply_noise(img_pil):\n",
        "    img = np.array(img_pil)\n",
        "    noise = np.random.normal(0, 25, img.shape).astype(np.uint8)\n",
        "    img = cv2.add(img, noise)\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "# 배경 로딩\n",
        "bg_list = []\n",
        "for s in bg_stages:\n",
        "    bg_list += list((root / f\"stage{s}\").glob(\"*.*\"))\n",
        "\n",
        "icons_black = list(icon_black_dir.glob(\"*.*\"))\n",
        "icons_white = list(icon_white_dir.glob(\"*.*\"))\n",
        "icons_color = list(icon_color_dir.glob(\"*.*\"))\n",
        "others = list(other_dir.glob(\"*.*\"))\n",
        "\n",
        "assert bg_list and icons_black and icons_white and others, \"❌ 필요한 데이터 없음\"\n",
        "\n",
        "blank_count = 0\n",
        "for idx in range(num_images):\n",
        "    bg_path = random.choice(bg_list)\n",
        "    bg = Image.open(bg_path).convert(\"RGB\").resize(fixed_bg_size)\n",
        "    img_w, img_h = bg.size\n",
        "    label_lines = []\n",
        "\n",
        "    case = random.choices(\n",
        "        [\"blank\", \"adult_only\", \"adult_many\", \"other_label\"],\n",
        "        weights=[0.10, 0.2, 0.4, 0.3],\n",
        "        k=1\n",
        "    )[0]\n",
        "\n",
        "    # blank\n",
        "    if case == \"blank\":\n",
        "        blank_count += 1\n",
        "        bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "        open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\").close()\n",
        "        continue\n",
        "\n",
        "    # adult_only (무라벨 또는 일부 other)\n",
        "    if case in [\"adult_only\", \"adult_many\", \"other_label\"]:\n",
        "        count = random.randint(2, 6) if case != \"adult_many\" else random.randint(6, 12)\n",
        "        for _ in range(count):\n",
        "            obj = Image.open(random.choice(others)).convert(\"RGBA\")\n",
        "            scale = random.uniform(1.0, 1.8)\n",
        "            obj = resize_with_padding(obj, int(base_other_size * scale))\n",
        "            w, h = obj.size\n",
        "            if w >= img_w or h >= img_h: continue\n",
        "            x, y = random.randint(0, img_w - w), random.randint(0, img_h - h)\n",
        "            bg.paste(obj, (x, y), obj)\n",
        "            if case == \"other_label\":\n",
        "                label_lines.append(f\"1 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    # 아이콘 일부러 넣는 경우 확률 ↑\n",
        "    if random.random() < 0.4:  # 40% 확률로 아이콘 추가\n",
        "        for _ in range(random.randint(1, 3)):\n",
        "            patch_w = patch_h = base_icon_size\n",
        "            x = random.randint(0, img_w - patch_w)\n",
        "            y = random.randint(0, img_h - patch_h)\n",
        "            patch = bg.crop((x, y, x + patch_w, y + patch_h))\n",
        "            bright = is_bright(patch)\n",
        "            candidates = icons_black if bright else icons_white\n",
        "            if candidates:\n",
        "                obj = Image.open(random.choice(candidates)).convert(\"RGBA\")\n",
        "                scale = random.uniform(0.3, 0.6)\n",
        "                obj = resize_keep_ratio(obj, int(base_icon_size * scale))\n",
        "                w, h = obj.size\n",
        "                if w < img_w and h < img_h:\n",
        "                    x = random.randint(0, img_w - w)\n",
        "                    y = random.randint(0, img_h - h)\n",
        "                    bg.paste(obj, (x, y), obj)\n",
        "                    label_lines.append(f\"0 {(x + w/2)/img_w:.6f} {(y + h/2)/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}\")\n",
        "\n",
        "    bg.save(out_img_dir / f\"{idx:04d}.jpg\")\n",
        "    with open(out_lbl_dir / f\"{idx:04d}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))"
      ],
      "metadata": {
        "id": "U9XFhNz7pmkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "IiSchhF4x4al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 학습\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "root = '/content/train_dataset'\n",
        "project_dir = '/content/icon_detector'\n",
        "base_model = 'yolov8s.pt'\n",
        "epochs_list = [20, 30, 30, 30, 30, 30, 35, 35, 30]  # 9단계까지\n",
        "val_count = 100\n",
        "\n",
        "# 1️⃣ train.txt 무작위 생성\n",
        "def create_shuffled_train_txt(stage_path):\n",
        "    img_dir = Path(stage_path) / \"images/train\"\n",
        "    out_path = Path(stage_path) / \"train.txt\"\n",
        "    img_list = sorted(glob.glob(str(img_dir / \"*.jpg\")))\n",
        "    random.shuffle(img_list)\n",
        "    with open(out_path, \"w\") as f:\n",
        "        f.write(\"\\n\".join(img_list))\n",
        "\n",
        "# 2️⃣ data.yaml 자동 생성\n",
        "def generate_data_yaml(root, total_steps=9):\n",
        "    for step in range(1, total_steps + 1):\n",
        "        step_dir = Path(root) / f\"step{step}\"\n",
        "        yaml_path = step_dir / \"data.yaml\"\n",
        "        with open(yaml_path, \"w\") as f:\n",
        "            f.write(f\"\"\"train: {step_dir}/train.txt\n",
        "val: {step_dir}/images/val\n",
        "nc: 2\n",
        "names: [\\\"icon\\\", \\\"other\\\"]\n",
        "\"\"\")\n",
        "\n",
        "# 3️⃣ val 이미지 + 라벨 복사\n",
        "def prepare_val_with_labels(root, total_steps=9, val_count=100):\n",
        "    for step in range(1, total_steps + 1):\n",
        "        img_train = Path(root) / f\"step{step}/images/train\"\n",
        "        lbl_train = Path(root) / f\"step{step}/labels/train\"\n",
        "        img_val = Path(root) / f\"step{step}/images/val\"\n",
        "        lbl_val = Path(root) / f\"step{step}/labels/val\"\n",
        "        img_val.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_val.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        img_paths = glob.glob(str(img_train / \"*.jpg\"))\n",
        "        picked = img_paths if len(img_paths) < val_count else random.sample(img_paths, val_count)\n",
        "\n",
        "        for img_path in picked:\n",
        "            name = Path(img_path).stem\n",
        "            lbl_path = lbl_train / f\"{name}.txt\"\n",
        "            shutil.copy(img_path, img_val / f\"{name}.jpg\")\n",
        "            if lbl_path.exists():\n",
        "                shutil.copy(lbl_path, lbl_val / f\"{name}.txt\")\n",
        "            else:\n",
        "                print(f\"❌ step{step}: 라벨 없음 → {name}.jpg만 복사됨\")\n",
        "        print(f\"✅ step{step}: val {len(picked)}장 복사 완료\")\n",
        "\n",
        "# 🔁 전체 준비 실행\n",
        "for step in range(1, 10):\n",
        "    create_shuffled_train_txt(f\"{root}/step{step}\")\n",
        "generate_data_yaml(root=root)\n",
        "prepare_val_with_labels(root=root, val_count=val_count)\n",
        "\n",
        "# 4️⃣ 학습 루프\n",
        "for stage in range(1, 10):\n",
        "    data_yaml = f'{root}/step{stage}/data.yaml'\n",
        "    run_name = f'stage{stage}'\n",
        "    epochs = epochs_list[stage - 1]\n",
        "\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"🚀 Stage {stage} 학습 시작\")\n",
        "    print(f\"📦 Epochs: {epochs}\")\n",
        "    print(f\"📁 data.yaml: {data_yaml}\")\n",
        "    print(f\"🧠 Checkpoint: {'초기모델' if stage == 1 else 'stage'+str(stage-1)}\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    if stage == 1:\n",
        "        model = YOLO(base_model)\n",
        "    else:\n",
        "        prev_best = Path(project_dir) / f'stage{stage-1}' / 'weights' / 'best.pt'\n",
        "        model = YOLO(str(prev_best))\n",
        "\n",
        "    model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=epochs,\n",
        "        imgsz=1280,\n",
        "        rect=True,\n",
        "        project=project_dir,\n",
        "        name=run_name,\n",
        "        exist_ok=True,\n",
        "        patience=0,\n",
        "        cos_lr=True,\n",
        "        lr0=0.01,\n",
        "        warmup_epochs=5,\n",
        "        weight_decay=0.001,\n",
        "        iou=0.7,\n",
        "        conf=0.4,\n",
        "        augment=True\n",
        "    )"
      ],
      "metadata": {
        "id": "j-bx1VxDWTTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653a2966-656e-41df-cecc-ef8f53c956f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ step1: val 100장 복사 완료\n",
            "✅ step2: val 100장 복사 완료\n",
            "✅ step3: val 100장 복사 완료\n",
            "✅ step4: val 100장 복사 완료\n",
            "✅ step5: val 100장 복사 완료\n",
            "✅ step6: val 100장 복사 완료\n",
            "✅ step7: val 100장 복사 완료\n",
            "✅ step8: val 100장 복사 완료\n",
            "✅ step9: val 100장 복사 완료\n",
            "\n",
            "==============================\n",
            "🚀 Stage 1 학습 시작\n",
            "📦 Epochs: 20\n",
            "📁 data.yaml: /content/train_dataset/step1/data.yaml\n",
            "🧠 Checkpoint: 초기모델\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step1/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1151.5±231.0 MB/s, size: 26.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step1/labels/train.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 410.9±225.7 MB/s, size: 46.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step1/labels/val... 177 images, 0 backgrounds, 0 corrupt: 100%|██████████| 177/177 [00:00<00:00, 1238.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step1/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage1\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      8.22G      2.109       3.76      1.322        128       1280: 100%|██████████| 13/13 [00:02<00:00,  5.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.283      0.381      0.189      0.117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      8.91G      1.321      1.225      1.006        129       1280: 100%|██████████| 13/13 [00:01<00:00,  6.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782        0.4      0.687       0.44      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      8.91G      1.071     0.8831     0.9449        127       1280: 100%|██████████| 13/13 [00:01<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.721      0.877      0.725      0.536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20      8.91G     0.9843       0.77     0.9077        125       1280: 100%|██████████| 13/13 [00:01<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.845      0.897      0.935      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      8.91G     0.9099     0.7163     0.8772        111       1280: 100%|██████████| 13/13 [00:01<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.888      0.896      0.941      0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      8.91G      0.899     0.6479     0.8827        128       1280: 100%|██████████| 13/13 [00:01<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.882       0.91       0.95      0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      8.91G     0.8426      0.605     0.8711        126       1280: 100%|██████████| 13/13 [00:01<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.866      0.899      0.948      0.751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      8.91G     0.7736     0.5347     0.8527        133       1280: 100%|██████████| 13/13 [00:01<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.955      0.954      0.976      0.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      8.91G     0.7992     0.5464     0.8596        116       1280: 100%|██████████| 13/13 [00:01<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.969       0.96      0.982      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      8.91G     0.7739     0.5269     0.8623        131       1280: 100%|██████████| 13/13 [00:01<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.977      0.962      0.982      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      8.91G     0.7469      0.494     0.8518        131       1280: 100%|██████████| 13/13 [00:02<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.978       0.97      0.986      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20      8.91G     0.7739     0.4981     0.8562        137       1280: 100%|██████████| 13/13 [00:01<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.981      0.975      0.989      0.859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      8.91G     0.6553     0.4504     0.8359        130       1280: 100%|██████████| 13/13 [00:01<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.982      0.972      0.987      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      8.91G     0.6184     0.4304     0.8302        126       1280: 100%|██████████| 13/13 [00:01<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.986      0.973      0.988      0.876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      8.91G     0.5987     0.4001     0.8237        111       1280: 100%|██████████| 13/13 [00:01<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.988      0.975      0.988      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      8.91G     0.5903     0.3972     0.8269        139       1280: 100%|██████████| 13/13 [00:01<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.989      0.975      0.988      0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      8.91G     0.5684     0.3878     0.8252        127       1280: 100%|██████████| 13/13 [00:01<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782       0.99      0.976      0.989        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      8.91G     0.5732     0.3736     0.8194        114       1280: 100%|██████████| 13/13 [00:01<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.989      0.975      0.989        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      8.91G      0.572     0.3751     0.8199        117       1280: 100%|██████████| 13/13 [00:01<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.987      0.976      0.989        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      8.91G     0.5507     0.3666     0.8174        122       1280: 100%|██████████| 13/13 [00:01<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.988      0.975      0.988      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage1/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage1/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage1/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:03<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        177       2782      0.969      0.972      0.985      0.872\n",
            "                  icon        177       1512      0.952      0.953      0.975       0.81\n",
            "                 other        177       1270      0.986      0.991      0.995      0.934\n",
            "Speed: 0.4ms preprocess, 8.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage1\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 2 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step2/data.yaml\n",
            "🧠 Checkpoint: stage1\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step2/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage1/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1032.2±418.9 MB/s, size: 36.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step2/labels/train.cache... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 340.5±114.7 MB/s, size: 40.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step2/labels/val... 208 images, 0 backgrounds, 0 corrupt: 100%|██████████| 208/208 [00:00<00:00, 1183.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step2/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      8.25G     0.7009     0.6173     0.8493        179       1280: 100%|██████████| 19/19 [00:03<00:00,  5.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.959      0.912      0.962      0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      8.96G      0.749     0.5536     0.8576        154       1280: 100%|██████████| 19/19 [00:02<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.959      0.923      0.968      0.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30         9G     0.7373     0.5215     0.8497        174       1280: 100%|██████████| 19/19 [00:02<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.951      0.912      0.952      0.812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      9.01G     0.7707     0.5418     0.8606        180       1280: 100%|██████████| 19/19 [00:02<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.968      0.932      0.969      0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      9.01G      0.804     0.5694     0.8649        151       1280: 100%|██████████| 19/19 [00:02<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.971      0.939      0.973      0.796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      9.03G      0.777     0.5607     0.8584        173       1280: 100%|██████████| 19/19 [00:02<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.945      0.914      0.961      0.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      9.03G     0.7865     0.5357     0.8689        165       1280: 100%|██████████| 19/19 [00:02<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.966      0.938      0.974      0.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      9.03G     0.7488     0.5151     0.8525        163       1280: 100%|██████████| 19/19 [00:02<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.957      0.936      0.968      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      9.07G     0.7345     0.4911       0.85        161       1280: 100%|██████████| 19/19 [00:02<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.975      0.946      0.979      0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      9.07G     0.7309     0.4876     0.8535        167       1280: 100%|██████████| 19/19 [00:02<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.967      0.951      0.978      0.845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      9.07G      0.728     0.4822     0.8479        169       1280: 100%|██████████| 19/19 [00:02<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.969      0.965      0.981      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      9.11G     0.7075     0.4715     0.8485        154       1280: 100%|██████████| 19/19 [00:02<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.986      0.961      0.984      0.851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      9.11G     0.6569     0.4405     0.8307        161       1280: 100%|██████████| 19/19 [00:02<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.983      0.968      0.985      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      9.11G     0.6745     0.4376     0.8388        143       1280: 100%|██████████| 19/19 [00:02<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.984      0.967      0.985      0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      9.14G     0.6431     0.4221     0.8302        152       1280: 100%|██████████| 19/19 [00:02<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987      0.968      0.985      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      9.14G      0.625     0.4073     0.8309        162       1280: 100%|██████████| 19/19 [00:02<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.975      0.969      0.985      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      9.14G     0.6087     0.3984     0.8242        175       1280: 100%|██████████| 19/19 [00:02<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387       0.98      0.977      0.989      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      9.18G     0.6137     0.3977     0.8255        170       1280: 100%|██████████| 19/19 [00:02<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.981      0.979      0.989      0.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      9.18G     0.6042      0.387     0.8205        191       1280: 100%|██████████| 19/19 [00:02<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987       0.98      0.989      0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      9.18G     0.5985     0.3843     0.8234        177       1280: 100%|██████████| 19/19 [00:02<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.988       0.98       0.99      0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      9.21G     0.5874     0.3667     0.8218        150       1280: 100%|██████████| 19/19 [00:03<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.986      0.975      0.987      0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      9.21G     0.5604     0.3587     0.8206        170       1280: 100%|██████████| 19/19 [00:02<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987      0.981       0.99      0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      9.21G     0.5449     0.3444     0.8111        173       1280: 100%|██████████| 19/19 [00:02<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987      0.985      0.991      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      9.21G     0.5295     0.3383     0.8084        179       1280: 100%|██████████| 19/19 [00:02<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.988      0.982      0.991      0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      9.21G     0.5452     0.3432     0.8154        160       1280: 100%|██████████| 19/19 [00:02<00:00,  6.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.991      0.981       0.99      0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      9.21G      0.528     0.3342     0.8142        182       1280: 100%|██████████| 19/19 [00:02<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387       0.99      0.982      0.991      0.914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      9.21G     0.5341     0.3401     0.8133        154       1280: 100%|██████████| 19/19 [00:02<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987      0.983      0.991      0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      9.21G     0.5072     0.3239     0.8116        168       1280: 100%|██████████| 19/19 [00:02<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.988      0.983      0.992      0.915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      9.21G     0.5111     0.3229     0.8106        172       1280: 100%|██████████| 19/19 [00:02<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.988      0.983      0.992       0.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      9.21G     0.5139     0.3246     0.8126        177       1280: 100%|██████████| 19/19 [00:02<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387      0.987      0.983      0.992      0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.038 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage2/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage2/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage2/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        208       3387       0.98      0.973      0.992      0.895\n",
            "                  icon        208       1818      0.968      0.958      0.989      0.834\n",
            "                 other        208       1569      0.992      0.989      0.995      0.956\n",
            "Speed: 0.3ms preprocess, 7.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage2\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 3 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step3/data.yaml\n",
            "🧠 Checkpoint: stage2\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step3/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage2/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2129.3±790.9 MB/s, size: 87.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step3/labels/train.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|██████████| 400/400 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 392.5±81.5 MB/s, size: 77.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step3/labels/val... 230 images, 0 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<00:00, 1184.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step3/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage3\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      8.29G     0.9801      1.055       1.03        379       1280: 100%|██████████| 25/25 [00:04<00:00,  5.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.869      0.699      0.814      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      9.91G     0.9324     0.8816     0.9964        404       1280: 100%|██████████| 25/25 [00:03<00:00,  6.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.875      0.711      0.826      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      9.91G     0.9147     0.8372     0.9839        397       1280: 100%|██████████| 25/25 [00:03<00:00,  6.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.881      0.745      0.852      0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      9.91G     0.9172     0.8144     0.9759        394       1280: 100%|██████████| 25/25 [00:03<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.859      0.768      0.852       0.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      9.91G     0.9082     0.8026     0.9662        416       1280: 100%|██████████| 25/25 [00:03<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.895      0.749      0.861      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      9.91G     0.8975     0.7847     0.9607        411       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227       0.88      0.766      0.861      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      9.93G     0.8743     0.7284     0.9501        410       1280: 100%|██████████| 25/25 [00:03<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.912      0.794      0.881      0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      9.93G     0.8943      0.752     0.9565        412       1280: 100%|██████████| 25/25 [00:03<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227       0.92      0.772       0.87      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      9.93G     0.8538     0.6907     0.9359        432       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.911      0.833      0.902      0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      9.93G     0.8258     0.6639     0.9329        431       1280: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.927      0.818      0.897      0.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      9.93G     0.8456     0.6811     0.9402        399       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.923      0.834      0.907      0.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      9.97G     0.8033     0.6433     0.9193        415       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.929      0.829      0.913      0.784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30        10G      0.773     0.6097     0.9128        427       1280: 100%|██████████| 25/25 [00:03<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.934      0.845       0.92      0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30        10G     0.7864      0.606     0.9226        415       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.945      0.849      0.917      0.797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30        10G     0.7653     0.5937     0.9085        399       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.962      0.853      0.921      0.812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30        10G     0.7402     0.5548     0.9043        406       1280: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.946      0.872      0.928      0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30        10G     0.7246     0.5294     0.8946        396       1280: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.954       0.88      0.934       0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30        10G     0.7237     0.5246     0.8932        353       1280: 100%|██████████| 25/25 [00:03<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.952      0.878      0.933      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30        10G      0.695     0.5052      0.891        405       1280: 100%|██████████| 25/25 [00:03<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.964      0.888       0.94      0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30        10G     0.7081     0.5103      0.886        409       1280: 100%|██████████| 25/25 [00:03<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.962      0.895      0.948      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      10.1G     0.6991     0.5019     0.8863        382       1280: 100%|██████████| 25/25 [00:04<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.969      0.892      0.947      0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      10.1G      0.653     0.4622     0.8709        410       1280: 100%|██████████| 25/25 [00:03<00:00,  6.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.971      0.904      0.949      0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      10.1G     0.6543     0.4545     0.8691        390       1280: 100%|██████████| 25/25 [00:03<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.961      0.919      0.956      0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      10.1G     0.6469      0.447     0.8685        401       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.968       0.92      0.957      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      10.1G     0.6513     0.4495      0.875        401       1280: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.972       0.92      0.957      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      10.1G     0.6202      0.428     0.8633        411       1280: 100%|██████████| 25/25 [00:03<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.977      0.919      0.959      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      10.1G     0.6223     0.4248     0.8624        380       1280: 100%|██████████| 25/25 [00:03<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.975      0.926      0.961      0.869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      10.1G     0.6279     0.4332     0.8608        379       1280: 100%|██████████| 25/25 [00:03<00:00,  6.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.979      0.924      0.962      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      10.1G     0.6102      0.418     0.8602        406       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.974       0.93      0.963       0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      10.1G      0.606     0.4138     0.8612        409       1280: 100%|██████████| 25/25 [00:03<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.974      0.931      0.964      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.047 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage3/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage3/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage3/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        230       6227      0.962      0.917      0.963      0.854\n",
            "                  icon        230       2568      0.957      0.947      0.976      0.833\n",
            "                 other        230       3659      0.968      0.888       0.95      0.874\n",
            "Speed: 0.3ms preprocess, 7.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage3\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 4 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step4/data.yaml\n",
            "🧠 Checkpoint: stage3\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step4/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage3/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2563.0±525.5 MB/s, size: 102.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step4/labels/train.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 806.1±402.6 MB/s, size: 116.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step4/labels/val... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 1174.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step4/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage4\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      8.41G     0.7145     0.5172     0.8863         89       1280: 100%|██████████| 32/32 [00:05<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.947      0.864      0.933      0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30        10G     0.7048     0.4896       0.88        110       1280: 100%|██████████| 32/32 [00:04<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.941      0.889      0.938      0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30        10G      0.723     0.4911     0.8807        114       1280: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.959      0.904      0.952      0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30        10G     0.7087     0.4891     0.8728        110       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612       0.96      0.884       0.94      0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30        10G     0.7426     0.5135     0.8777        113       1280: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.956      0.892      0.948       0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30        10G     0.7349     0.5163     0.8767        101       1280: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.965      0.908      0.955      0.845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30        10G     0.7069     0.4813     0.8681         98       1280: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.952      0.903       0.95      0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      10.1G     0.7002     0.4733     0.8656        100       1280: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.966      0.918       0.96      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      10.1G     0.6777     0.4572     0.8651         96       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.968      0.918       0.96      0.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      10.1G     0.6704     0.4408     0.8569         96       1280: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.969      0.921      0.961      0.838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      10.2G     0.6698     0.4415     0.8579         97       1280: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.968      0.914       0.96      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      10.2G     0.6439     0.4235     0.8506         98       1280: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.974      0.936      0.968      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      10.2G     0.6217     0.4086     0.8528        106       1280: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.972      0.943      0.969      0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      10.3G     0.6125      0.403     0.8426        102       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.976      0.936      0.968      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      10.3G     0.6068     0.4002     0.8438        104       1280: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.972      0.947      0.972      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      10.3G     0.5946     0.3915     0.8425         95       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.975      0.949      0.978      0.876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      10.3G     0.6097     0.3889     0.8427        105       1280: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.977       0.94      0.974      0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      10.3G     0.5992     0.3824     0.8342         95       1280: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.977      0.956      0.977      0.882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      10.3G     0.5656     0.3681     0.8336         98       1280: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.983      0.954      0.978        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      10.3G     0.5698      0.366     0.8307        104       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.984       0.96      0.981      0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      10.3G      0.548     0.3567     0.8285         99       1280: 100%|██████████| 32/32 [00:05<00:00,  5.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.979      0.961       0.98      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      10.3G     0.5322     0.3404     0.8245        104       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.984      0.958      0.981      0.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      10.3G     0.5251     0.3382     0.8235        109       1280: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.983      0.961      0.983      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      10.3G     0.5279     0.3392     0.8249        104       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.985      0.962      0.982      0.908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      10.3G     0.5174     0.3317     0.8245         95       1280: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.988      0.961      0.983      0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      10.3G     0.5203     0.3323     0.8183        114       1280: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.989      0.963      0.982      0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      10.3G     0.5018     0.3224     0.8207         96       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.988      0.961      0.982      0.914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      10.3G     0.5092      0.327     0.8202        114       1280: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612       0.99      0.963      0.984      0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      10.3G     0.5024     0.3233       0.82        110       1280: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612       0.99      0.964      0.984      0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      10.3G     0.4988     0.3205      0.819         98       1280: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.991      0.964      0.984      0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.056 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage4/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage4/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage4/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        240       7612      0.979      0.958      0.986      0.904\n",
            "                  icon        240       4427      0.984      0.962      0.988      0.884\n",
            "                 other        240       3185      0.974      0.955      0.984      0.923\n",
            "Speed: 0.4ms preprocess, 6.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage4\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 5 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step5/data.yaml\n",
            "🧠 Checkpoint: stage4\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step5/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage4/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2313.0±729.3 MB/s, size: 113.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step5/labels/train.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 517.6±82.4 MB/s, size: 125.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step5/labels/val... 247 images, 0 backgrounds, 0 corrupt: 100%|██████████| 247/247 [00:00<00:00, 1166.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step5/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage5\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30       8.5G     0.7827     0.7369     0.9433        100       1280: 100%|██████████| 32/32 [00:05<00:00,  5.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423       0.91      0.779       0.87      0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      10.1G      0.739     0.6002      0.913        130       1280: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.904      0.826      0.896      0.788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      10.1G     0.7366      0.561     0.9041        131       1280: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.923      0.833      0.914      0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      10.1G     0.7659     0.5724     0.9055        127       1280: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.927      0.848      0.917      0.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      10.1G     0.7497     0.5543     0.9004        127       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423       0.94      0.863      0.926      0.817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      10.1G     0.7416     0.5518     0.8973        118       1280: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.936      0.857      0.926      0.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      10.1G     0.7343     0.5304     0.8873        107       1280: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423       0.95      0.871      0.933      0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      10.1G     0.7294     0.5198     0.8889        111       1280: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.956      0.876      0.941      0.828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      10.1G     0.7153     0.5088      0.885        111       1280: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.951      0.881      0.939       0.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      10.2G     0.6988     0.4913     0.8767        109       1280: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.969      0.893      0.947      0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      10.2G     0.6841     0.4734     0.8778        114       1280: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.961      0.908      0.952      0.851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      10.3G     0.6856     0.4736     0.8734        103       1280: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.968      0.906      0.953      0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      10.3G     0.6565     0.4425     0.8677        126       1280: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.962      0.913      0.953      0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      10.3G     0.6554      0.438     0.8619        109       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.969      0.912      0.959      0.857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      10.4G     0.6475     0.4352     0.8623        124       1280: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.973      0.919      0.959       0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      10.4G     0.6272     0.4225     0.8537        100       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.974      0.914       0.96      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      10.4G     0.6277     0.4153     0.8537        121       1280: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.976      0.921      0.964      0.864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      10.4G     0.6083     0.3996     0.8488        114       1280: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.981      0.923      0.964      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      10.4G     0.6017     0.3978     0.8498        113       1280: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.982      0.931      0.966      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      10.4G     0.5963     0.3913      0.847        122       1280: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.976      0.934      0.967      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      10.4G     0.5837     0.3837      0.843        115       1280: 100%|██████████| 32/32 [00:05<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.982      0.937      0.969      0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      10.4G     0.5637     0.3683     0.8346        124       1280: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.981      0.947      0.972      0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      10.4G     0.5499     0.3594     0.8366        123       1280: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.983      0.944      0.971      0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      10.4G     0.5579     0.3686     0.8351        124       1280: 100%|██████████| 32/32 [00:05<00:00,  6.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.984      0.945      0.974      0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      10.4G     0.5386     0.3526     0.8364        110       1280: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423       0.98      0.949      0.973      0.894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      10.4G     0.5506     0.3558     0.8337        132       1280: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.983       0.95      0.974      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      10.4G     0.5252      0.344     0.8328        103       1280: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.981      0.951      0.974      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      10.4G     0.5336     0.3493     0.8307        132       1280: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.985      0.947      0.974      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      10.4G     0.5305      0.344     0.8316        125       1280: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423       0.98      0.953      0.975      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      10.4G     0.5218     0.3432     0.8304        116       1280: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.984      0.949      0.975      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.057 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage5/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage5/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage5/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:05<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        247       8423      0.976      0.942      0.976      0.889\n",
            "                  icon        247       3891      0.967      0.931       0.97      0.857\n",
            "                 other        247       4532      0.984      0.954      0.982       0.92\n",
            "Speed: 0.3ms preprocess, 5.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage5\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 6 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step6/data.yaml\n",
            "🧠 Checkpoint: stage5\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step6/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage5/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2059.6±748.0 MB/s, size: 108.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step6/labels/train.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|██████████| 400/400 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 662.6±422.2 MB/s, size: 93.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step6/labels/val... 233 images, 0 backgrounds, 0 corrupt: 100%|██████████| 233/233 [00:00<00:00, 1388.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step6/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage6\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      8.09G     0.5899     0.4351     0.8672        241       1280: 100%|██████████| 25/25 [00:04<00:00,  5.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.965      0.926      0.961       0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      9.74G     0.6194     0.4346     0.8734        269       1280: 100%|██████████| 25/25 [00:03<00:00,  6.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.952       0.92      0.957      0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      9.74G     0.6415     0.4443     0.8776        248       1280: 100%|██████████| 25/25 [00:03<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.944      0.896      0.948      0.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      9.74G     0.6546     0.4629     0.8818        257       1280: 100%|██████████| 25/25 [00:03<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.941      0.916      0.959      0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      9.77G     0.6852     0.4941     0.8867        263       1280: 100%|██████████| 25/25 [00:04<00:00,  5.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.933      0.907      0.946      0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      9.77G     0.6846      0.495     0.8892        262       1280: 100%|██████████| 25/25 [00:03<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.952      0.902      0.955       0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      9.77G     0.6716     0.4753     0.8823        270       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.968      0.911      0.965      0.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30       9.8G     0.6723     0.4813     0.8829        262       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.953      0.916      0.964      0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30       9.8G     0.6724     0.4608     0.8817        273       1280: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.975      0.929      0.966       0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30       9.8G     0.6333     0.4426     0.8696        283       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.971       0.93      0.963      0.866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30       9.8G     0.6469     0.4582     0.8727        254       1280: 100%|██████████| 25/25 [00:03<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674       0.98      0.914      0.966      0.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30       9.8G     0.6461     0.4417     0.8702        259       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.976      0.921      0.964      0.861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      9.84G     0.6076     0.4194     0.8558        278       1280: 100%|██████████| 25/25 [00:03<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.971       0.94      0.974      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      9.84G     0.6008     0.4094     0.8646        253       1280: 100%|██████████| 25/25 [00:03<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.979      0.945      0.975      0.889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      9.84G     0.5901     0.4052     0.8534        265       1280: 100%|██████████| 25/25 [00:03<00:00,  6.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.984      0.941      0.974      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      9.84G     0.5801     0.3876     0.8524        261       1280: 100%|██████████| 25/25 [00:03<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.979      0.954      0.976      0.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      9.88G     0.5584     0.3719     0.8485        256       1280: 100%|██████████| 25/25 [00:03<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.986      0.949      0.977      0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      9.88G     0.5548      0.369     0.8446        218       1280: 100%|██████████| 25/25 [00:03<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674       0.98      0.958      0.982      0.902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      9.88G     0.5346     0.3562     0.8432        267       1280: 100%|██████████| 25/25 [00:03<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.983      0.964      0.981      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      9.88G     0.5315     0.3561     0.8414        256       1280: 100%|██████████| 25/25 [00:03<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.979      0.965      0.983      0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      9.91G     0.5171     0.3478     0.8389        238       1280: 100%|██████████| 25/25 [00:04<00:00,  5.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.985      0.961      0.982      0.909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      9.95G     0.4917     0.3278     0.8312        269       1280: 100%|██████████| 25/25 [00:03<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.984      0.966      0.984      0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      9.95G     0.4809     0.3227     0.8289        249       1280: 100%|██████████| 25/25 [00:03<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.983      0.967      0.984      0.917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      9.95G     0.4831     0.3211     0.8283        261       1280: 100%|██████████| 25/25 [00:03<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.989      0.964      0.985      0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      9.95G     0.4755      0.323     0.8281        261       1280: 100%|██████████| 25/25 [00:03<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.993      0.962      0.986      0.926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      9.95G     0.4631     0.3103     0.8253        266       1280: 100%|██████████| 25/25 [00:03<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.987      0.968      0.986      0.926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      9.95G     0.4584     0.3035     0.8276        238       1280: 100%|██████████| 25/25 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674       0.99      0.966      0.986      0.926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      9.95G     0.4604     0.3123      0.824        238       1280: 100%|██████████| 25/25 [00:03<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.993      0.963      0.986      0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      9.95G     0.4478     0.2995     0.8227        260       1280: 100%|██████████| 25/25 [00:03<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.989      0.967      0.986      0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      9.95G     0.4447     0.2985     0.8196        262       1280: 100%|██████████| 25/25 [00:03<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.989      0.967      0.986      0.929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.047 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage6/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage6/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage6/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        233       4674      0.979      0.966      0.987      0.915\n",
            "                  icon        218       1444      0.976       0.97      0.988      0.897\n",
            "                 other        233       3230      0.982      0.962      0.987      0.932\n",
            "Speed: 0.3ms preprocess, 7.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage6\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 7 학습 시작\n",
            "📦 Epochs: 35\n",
            "📁 data.yaml: /content/train_dataset/step7/data.yaml\n",
            "🧠 Checkpoint: stage6\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step7/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=35, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage6/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1641.9±712.5 MB/s, size: 71.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step7/labels/train.cache... 300 images, 2 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 657.7±576.7 MB/s, size: 77.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step7/labels/val... 206 images, 2 backgrounds, 0 corrupt: 100%|██████████| 206/206 [00:00<00:00, 1110.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step7/labels/val.cache\n",
            "Plotting labels to /content/icon_detector/stage7/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage7\u001b[0m\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/35      8.37G     0.5894     0.4304     0.8702        319       1280: 100%|██████████| 19/19 [00:03<00:00,  5.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.958      0.916      0.959      0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/35      9.98G     0.5981     0.4293     0.8651        279       1280: 100%|██████████| 19/19 [00:02<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.965      0.921      0.961      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/35      9.98G     0.6104     0.4266     0.8614        314       1280: 100%|██████████| 19/19 [00:02<00:00,  6.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.968      0.929      0.964      0.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/35      9.98G     0.6101     0.4238     0.8607        309       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.966      0.923      0.965      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/35      9.98G     0.6348      0.439     0.8633        294       1280: 100%|██████████| 19/19 [00:02<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.966      0.926      0.964      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/35      9.98G     0.6386     0.4384     0.8667        310       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.938      0.881      0.945      0.839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/35      9.98G     0.6913       0.48     0.8797        307       1280: 100%|██████████| 19/19 [00:02<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.959      0.914      0.958      0.858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/35      9.98G     0.6892     0.4632      0.873        298       1280: 100%|██████████| 19/19 [00:02<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.962      0.916      0.959      0.863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/35        10G     0.6445     0.4307     0.8651        313       1280: 100%|██████████| 19/19 [00:02<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.976      0.932       0.97      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/35        10G     0.6007     0.4091     0.8578        305       1280: 100%|██████████| 19/19 [00:02<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.956      0.898      0.954      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/35        10G     0.6019     0.4137     0.8501        311       1280: 100%|██████████| 19/19 [00:02<00:00,  6.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.976      0.928      0.968      0.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/35        10G     0.5851     0.3965     0.8525        293       1280: 100%|██████████| 19/19 [00:02<00:00,  6.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.971       0.93      0.966      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/35        10G      0.582     0.3929     0.8479        293       1280: 100%|██████████| 19/19 [00:02<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927       0.97      0.926      0.965      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/35        10G     0.6108     0.4237     0.8615        258       1280: 100%|██████████| 19/19 [00:02<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.982       0.94      0.973      0.886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/35      10.1G     0.5979     0.4026     0.8524        288       1280: 100%|██████████| 19/19 [00:02<00:00,  6.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.982      0.941      0.973       0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/35      10.1G      0.592     0.3958     0.8493        282       1280: 100%|██████████| 19/19 [00:02<00:00,  6.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.977      0.933      0.968      0.879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/35      10.1G      0.558     0.3731     0.8389        313       1280: 100%|██████████| 19/19 [00:02<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927       0.98      0.947      0.976      0.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/35      10.1G     0.5614     0.3666     0.8439        304       1280: 100%|██████████| 19/19 [00:02<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.983      0.949      0.977        0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/35      10.1G     0.5585     0.3614      0.843        344       1280: 100%|██████████| 19/19 [00:02<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.976      0.958      0.978      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/35      10.1G     0.5563     0.3632     0.8414        322       1280: 100%|██████████| 19/19 [00:02<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.985       0.95      0.978      0.901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/35      10.1G     0.5454     0.3533     0.8368        280       1280: 100%|██████████| 19/19 [00:02<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.984      0.951       0.98       0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/35      10.1G     0.5294     0.3491     0.8361        277       1280: 100%|██████████| 19/19 [00:02<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.985      0.953      0.978      0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/35      10.2G     0.5273     0.3422     0.8311        303       1280: 100%|██████████| 19/19 [00:02<00:00,  6.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.987      0.956      0.982      0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/35      10.2G     0.5063     0.3263     0.8294        308       1280: 100%|██████████| 19/19 [00:02<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.989      0.957      0.981      0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/35      10.2G     0.4971     0.3251     0.8258        300       1280: 100%|██████████| 19/19 [00:02<00:00,  6.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.986      0.964      0.981      0.914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/35      10.2G     0.4911     0.3223     0.8256        287       1280: 100%|██████████| 19/19 [00:03<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.991      0.964      0.983      0.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/35      10.2G     0.4781     0.3136     0.8228        322       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.991      0.963      0.983       0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/35      10.2G     0.4725     0.3031     0.8221        319       1280: 100%|██████████| 19/19 [00:02<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.988      0.962      0.983      0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/35      10.2G     0.4682     0.3023     0.8228        318       1280: 100%|██████████| 19/19 [00:02<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.991      0.961      0.984      0.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/35      10.2G     0.4675     0.3067     0.8231        282       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.993      0.962      0.984      0.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/35      10.2G      0.476     0.3113     0.8224        326       1280: 100%|██████████| 19/19 [00:02<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.992      0.964      0.984      0.925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/35      10.2G     0.4669     0.3101     0.8239        278       1280: 100%|██████████| 19/19 [00:02<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927       0.99      0.966      0.985      0.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/35      10.2G     0.4535     0.2975     0.8143        310       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.991      0.966      0.985      0.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/35      10.2G     0.4576     0.2994     0.8168        308       1280: 100%|██████████| 19/19 [00:02<00:00,  6.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927       0.99      0.967      0.985      0.926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/35      10.2G     0.4628     0.3027     0.8157        310       1280: 100%|██████████| 19/19 [00:02<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.989      0.968      0.985      0.927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "35 epochs completed in 0.045 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage7/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage7/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage7/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        206       4927      0.983       0.96      0.986      0.913\n",
            "                  icon        198       2115      0.977      0.966      0.987      0.893\n",
            "                 other        201       2812      0.989      0.954      0.984      0.933\n",
            "Speed: 0.4ms preprocess, 7.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage7\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 8 학습 시작\n",
            "📦 Epochs: 35\n",
            "📁 data.yaml: /content/train_dataset/step8/data.yaml\n",
            "🧠 Checkpoint: stage7\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step8/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=35, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage7/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2696.4±1079.5 MB/s, size: 420.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step8/labels/train.cache... 600 images, 3 backgrounds, 0 corrupt: 100%|██████████| 600/600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 614.3±110.4 MB/s, size: 298.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step8/labels/val... 254 images, 3 backgrounds, 0 corrupt: 100%|██████████| 254/254 [00:00<00:00, 1316.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step8/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage8/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage8\u001b[0m\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/35      8.37G      1.091      1.086      1.087        168       1280: 100%|██████████| 38/38 [00:06<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.862      0.676      0.799      0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/35      9.98G     0.9287     0.7882     0.9996        193       1280: 100%|██████████| 38/38 [00:05<00:00,  6.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.894      0.726      0.841      0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/35      9.98G     0.8989     0.7334     0.9718        195       1280: 100%|██████████| 38/38 [00:05<00:00,  6.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.856      0.717      0.824      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/35      9.98G     0.9092     0.7385     0.9795        180       1280: 100%|██████████| 38/38 [00:05<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.908      0.769      0.869      0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/35      9.98G     0.8953     0.7328     0.9731        189       1280: 100%|██████████| 38/38 [00:05<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.905      0.778      0.868      0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/35        10G     0.8824     0.6954     0.9589        182       1280: 100%|██████████| 38/38 [00:05<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.904      0.746       0.85      0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/35        10G     0.8608      0.696     0.9572        150       1280: 100%|██████████| 38/38 [00:05<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.961      0.781      0.883      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/35        10G     0.8433     0.6712     0.9509        184       1280: 100%|██████████| 38/38 [00:05<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.924      0.794      0.888      0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/35        10G     0.8432      0.657     0.9478        163       1280: 100%|██████████| 38/38 [00:05<00:00,  6.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968       0.92      0.796      0.886       0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/35        10G      0.831     0.6488     0.9479        166       1280: 100%|██████████| 38/38 [00:05<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.938      0.829      0.907      0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/35        10G     0.8048     0.6092      0.936        188       1280: 100%|██████████| 38/38 [00:05<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.919      0.778      0.873      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/35        10G     0.8173     0.6054     0.9295        200       1280: 100%|██████████| 38/38 [00:05<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968       0.92       0.79       0.88      0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/35      10.1G     0.8004     0.5976     0.9292        199       1280: 100%|██████████| 38/38 [00:05<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.942      0.833      0.911      0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/35      10.1G     0.7705     0.5737     0.9207        198       1280: 100%|██████████| 38/38 [00:05<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.932      0.836      0.907      0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/35      10.1G     0.7681     0.5645     0.9169        193       1280: 100%|██████████| 38/38 [00:05<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.934      0.842      0.914      0.782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/35      10.1G     0.7603     0.5526      0.911        187       1280: 100%|██████████| 38/38 [00:05<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.954      0.854      0.923      0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/35      10.1G     0.7499     0.5455     0.9075        195       1280: 100%|██████████| 38/38 [00:05<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.959       0.86      0.924      0.812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/35      10.1G     0.7417      0.534      0.907        168       1280: 100%|██████████| 38/38 [00:05<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.953      0.865      0.927      0.814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/35      10.1G     0.7465     0.5342     0.9075        197       1280: 100%|██████████| 38/38 [00:05<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.958      0.848       0.92      0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/35      10.1G     0.7236     0.5204     0.9011        197       1280: 100%|██████████| 38/38 [00:05<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.973      0.851      0.922      0.815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/35      10.1G     0.7107     0.5124     0.8974        206       1280: 100%|██████████| 38/38 [00:05<00:00,  6.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.967      0.869      0.934      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/35      10.1G     0.6994     0.5008     0.8914        168       1280: 100%|██████████| 38/38 [00:05<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.957      0.875      0.932      0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/35      10.2G     0.6878      0.491     0.8904        210       1280: 100%|██████████| 38/38 [00:05<00:00,  6.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.971      0.871      0.933      0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/35      10.2G     0.6693     0.4705     0.8866        184       1280: 100%|██████████| 38/38 [00:05<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968       0.96      0.881      0.938      0.824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/35      10.2G     0.6614     0.4585     0.8736        167       1280: 100%|██████████| 38/38 [00:05<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.966      0.878      0.937      0.831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/35      10.2G     0.6675     0.4625      0.878        209       1280: 100%|██████████| 38/38 [00:06<00:00,  5.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968       0.97      0.889      0.945      0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/35      10.2G     0.6447     0.4421     0.8712        200       1280: 100%|██████████| 38/38 [00:05<00:00,  6.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.963      0.892      0.942       0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/35      10.2G     0.6548     0.4512     0.8785        204       1280: 100%|██████████| 38/38 [00:05<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.971      0.894      0.947      0.843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/35      10.2G     0.6487     0.4426     0.8759        189       1280: 100%|██████████| 38/38 [00:05<00:00,  6.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.974      0.894      0.948      0.849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/35      10.2G     0.6326     0.4322     0.8704        197       1280: 100%|██████████| 38/38 [00:05<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.977      0.896      0.948      0.852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/35      10.2G     0.6322      0.427     0.8701        180       1280: 100%|██████████| 38/38 [00:05<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.975      0.896      0.948      0.852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/35      10.2G     0.6297     0.4304     0.8713        194       1280: 100%|██████████| 38/38 [00:05<00:00,  6.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.973        0.9       0.95      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/35      10.2G      0.632     0.4384     0.8706        208       1280: 100%|██████████| 38/38 [00:05<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.974      0.899       0.95      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/35      10.2G     0.6258     0.4263     0.8673        188       1280: 100%|██████████| 38/38 [00:05<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.975      0.898       0.95      0.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/35      10.2G     0.6322     0.4389     0.8759        180       1280: 100%|██████████| 38/38 [00:05<00:00,  6.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.974      0.898       0.95      0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "35 epochs completed in 0.075 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage8/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage8/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage8/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        254       5968      0.952      0.901      0.952      0.844\n",
            "                  icon        236       2344       0.94      0.888      0.943      0.807\n",
            "                 other        249       3624      0.964      0.913       0.96      0.881\n",
            "Speed: 0.4ms preprocess, 7.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage8\u001b[0m\n",
            "\n",
            "==============================\n",
            "🚀 Stage 9 학습 시작\n",
            "📦 Epochs: 30\n",
            "📁 data.yaml: /content/train_dataset/step9/data.yaml\n",
            "🧠 Checkpoint: stage8\n",
            "==============================\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=0.4, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/train_dataset/step9/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/icon_detector/stage8/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage9, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/icon_detector, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/icon_detector/stage9, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1315.4±426.2 MB/s, size: 63.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_dataset/step9/labels/train... 500 images, 226 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<00:00, 1741.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train_dataset/step9/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 539.6±133.7 MB/s, size: 75.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_dataset/step9/labels/val... 187 images, 78 backgrounds, 0 corrupt: 100%|██████████| 187/187 [00:00<00:00, 1400.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/train_dataset/step9/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/icon_detector/stage9/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/icon_detector/stage9\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      8.23G     0.6466      5.592     0.8595          5       1280: 100%|██████████| 32/32 [00:05<00:00,  6.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.422      0.665      0.511      0.423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      9.84G     0.6447      1.491     0.8551          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387       0.97       0.39      0.443      0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      9.85G     0.6959      1.429     0.8633          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.487      0.398      0.451      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      9.89G     0.7044      1.417     0.8663          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.466      0.387      0.435      0.332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      9.93G     0.7654      1.491     0.8895          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.733      0.415      0.581      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      9.96G     0.7857       1.38     0.8785          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.918      0.396      0.515      0.359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30        10G      0.759      1.453      0.873          5       1280: 100%|██████████| 32/32 [00:04<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.963      0.403      0.492      0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30        10G     0.7612      1.415     0.8708          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.518      0.456      0.511       0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      10.1G     0.7556      1.406     0.8672          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.486      0.429      0.464      0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      10.1G     0.7265      1.419     0.8666          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.496      0.391      0.445      0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      10.1G     0.6956      1.328     0.8688          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.949      0.401      0.534      0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      10.2G     0.7323      1.355     0.8656          5       1280: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.973      0.408      0.602      0.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      10.2G     0.7416      1.308     0.8644          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.492      0.418      0.458      0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      10.3G     0.7337      1.304     0.8573          5       1280: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387       0.75      0.439      0.593      0.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      10.3G     0.6499      1.205     0.8585          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.701       0.52      0.596      0.488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      10.3G      0.643      1.194     0.8548          5       1280: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.691      0.527      0.606      0.525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      10.4G      0.622      1.143     0.8309          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.785      0.504      0.637      0.558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      10.4G     0.6012      1.089     0.8327          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387       0.76      0.622      0.655      0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      10.4G     0.5616      1.046     0.8326          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.721      0.696      0.685      0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      10.5G     0.5454      1.006     0.8244          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.806       0.64      0.721      0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      10.5G     0.5405     0.9466     0.8259          7       1280: 100%|██████████| 32/32 [00:05<00:00,  5.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387       0.76      0.678      0.715      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      10.5G     0.5162     0.9393     0.8124          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.767      0.807      0.785      0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      10.6G     0.4979     0.8253      0.815          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.801      0.748      0.791      0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      10.6G     0.4896     0.7785     0.8102          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.748      0.883      0.834      0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      10.7G     0.4804     0.7277     0.8033          5       1280: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.801      0.837      0.849      0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      10.7G     0.4757     0.7148     0.8118          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.797      0.886      0.871      0.797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      10.7G     0.4767     0.7128      0.817          6       1280: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.822      0.871      0.877      0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      10.8G     0.4713     0.7051     0.8104          7       1280: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.821      0.881      0.884      0.809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      10.8G     0.4753     0.6999     0.8057          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387       0.83      0.873      0.887      0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      10.8G     0.4632     0.6436     0.8151          7       1280: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:00<00:00,  6.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.821      0.891      0.891      0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.049 hours.\n",
            "Optimizer stripped from /content/icon_detector/stage9/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/icon_detector/stage9/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/icon_detector/stage9/weights/best.pt...\n",
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:01<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        187        387      0.877      0.863      0.913      0.818\n",
            "                  icon         77        141      0.959      0.957       0.98      0.839\n",
            "                 other         62        246      0.796      0.768      0.846      0.797\n",
            "Speed: 0.3ms preprocess, 6.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/icon_detector/stage9\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능 측정"
      ],
      "metadata": {
        "id": "tg5BqtzOx9yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "val_path = \"/content/test_dataset/test_data/images\"\n",
        "yaml_path = Path(\"/content/test_dataset/test_data/data.yaml\")\n",
        "yaml_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(\"/content/test_dataset/test_data/data.yaml\", \"w\") as f:\n",
        "    f.write(\n",
        "        \"train: dummy\\n\"\n",
        "        \"val: /content/test_dataset/test_data/test_data/images\\n\\n\"\n",
        "        \"nc: 2\\n\"\n",
        "        \"names: [\\\"icon\\\", \\\"other\\\"]\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"✅ 성능 측정용 data.yaml 생성 완료\")"
      ],
      "metadata": {
        "id": "q4rDvIEjWSVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c21072-05f1-47d8-c84b-fe21b3b13529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 성능 측정용 data.yaml 생성 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('icon_detector/stage4/weights/best.pt')\n",
        "\n",
        "# 📊 아이콘(class 0)만 성능 측정\n",
        "metrics = model.val(\n",
        "    data='/content/test_dataset/test_data/data.yaml',  # ✅ 수정됨\n",
        "    conf=0.1,\n",
        "    iou=0.7,\n",
        "    classes=[0]  # icon만 평가\n",
        ")\n",
        "\n",
        "\n",
        "# 📁 예측 수행 및 저장\n",
        "results = model.predict(\n",
        "    source='/content/test_dataset/test_data/test_data/images',\n",
        "    conf=0.1,\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    project='runs/detect',\n",
        "    name='val',\n",
        "    exist_ok=False\n",
        ")\n",
        "\n",
        "# 📌 성능 수치 출력\n",
        "print(\"\\n📊 [ICON ONLY] 성능 측정 결과:\")\n",
        "for k, v in metrics.results_dict.items():\n",
        "    print(f\"{k:<25}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "8KHMKnC_Y1BB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77b10a7-5f51-4686-b30f-64dbd162d3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2821.8±626.7 MB/s, size: 715.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/test_dataset/test_data/test_data/labels.cache... 118 images, 7 backgrounds, 0 corrupt: 100%|██████████| 125/125 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        125       2794      0.357      0.364      0.263     0.0904\n",
            "                  icon        116       2794      0.357      0.364      0.263     0.0904\n",
            "Speed: 3.6ms preprocess, 2.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "\n",
            "image 1/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.45.19 PM.png: 736x1280 23 icons, 11 others, 8.9ms\n",
            "image 2/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.51.34 PM.png: 736x1280 13 icons, 7 others, 8.1ms\n",
            "image 3/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.51.53 PM.png: 736x1280 17 icons, 11 others, 8.1ms\n",
            "image 4/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.53.33 PM.png: 736x1280 42 icons, 28 others, 8.1ms\n",
            "image 5/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.55.53 PM.png: 736x1280 45 icons, 12 others, 8.1ms\n",
            "image 6/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 4.58.36 PM.png: 736x1280 35 icons, 14 others, 8.2ms\n",
            "image 7/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 5.13.55 PM.png: 736x1280 52 icons, 27 others, 8.9ms\n",
            "image 8/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-09 at 5.28.11 PM.png: 736x1280 52 icons, 17 others, 8.2ms\n",
            "image 9/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.38.40 PM.png: 736x1280 11 icons, 7 others, 8.3ms\n",
            "image 10/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.39.59 PM.png: 736x1280 13 icons, 11 others, 8.0ms\n",
            "image 11/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.40.42 PM.png: 736x1280 17 icons, 10 others, 10.2ms\n",
            "image 12/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.41.30 PM.png: 736x1280 39 icons, 6 others, 7.9ms\n",
            "image 13/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.45.22 PM.png: 736x1280 9 icons, 7 others, 8.0ms\n",
            "image 14/125 /content/test_dataset/test_data/test_data/images/Screenshot 2025-06-10 at 1.46.30 PM.png: 736x1280 25 icons, 10 others, 8.1ms\n",
            "image 15/125 /content/test_dataset/test_data/test_data/images/a025733.png: 768x1280 35 icons, 3 others, 9.0ms\n",
            "image 16/125 /content/test_dataset/test_data/test_data/images/a030105.png: 768x1280 51 icons, 1 other, 8.2ms\n",
            "image 17/125 /content/test_dataset/test_data/test_data/images/a030125.png: 736x1280 76 icons, 9 others, 8.8ms\n",
            "image 18/125 /content/test_dataset/test_data/test_data/images/a030158.png: 768x1280 24 icons, 3 others, 8.9ms\n",
            "image 19/125 /content/test_dataset/test_data/test_data/images/a030259.png: 768x1280 113 icons, 23 others, 8.2ms\n",
            "image 20/125 /content/test_dataset/test_data/test_data/images/a030425.png: 768x1280 26 icons, 3 others, 12.5ms\n",
            "image 21/125 /content/test_dataset/test_data/test_data/images/a030708.png: 768x1280 48 icons, 7 others, 8.4ms\n",
            "image 22/125 /content/test_dataset/test_data/test_data/images/a030937.png: 768x1280 53 icons, 8 others, 8.3ms\n",
            "image 23/125 /content/test_dataset/test_data/test_data/images/a031041.png: 768x1280 60 icons, 18 others, 8.2ms\n",
            "image 24/125 /content/test_dataset/test_data/test_data/images/a031123.png: 768x1280 37 icons, 7 others, 8.4ms\n",
            "image 25/125 /content/test_dataset/test_data/test_data/images/a031451.png: 768x1280 61 icons, 18 others, 8.3ms\n",
            "image 26/125 /content/test_dataset/test_data/test_data/images/a031510.png: 768x1280 75 icons, 24 others, 8.1ms\n",
            "image 27/125 /content/test_dataset/test_data/test_data/images/a115252.png: 736x1280 61 icons, 25 others, 8.6ms\n",
            "image 28/125 /content/test_dataset/test_data/test_data/images/aaa1.png: 640x1280 3 icons, 6 others, 9.3ms\n",
            "image 29/125 /content/test_dataset/test_data/test_data/images/aaa2.png: 640x1280 12 icons, 11 others, 8.0ms\n",
            "image 30/125 /content/test_dataset/test_data/test_data/images/aaa3.png: 640x1280 40 icons, 11 others, 8.0ms\n",
            "image 31/125 /content/test_dataset/test_data/test_data/images/aaaa.png: 608x1280 21 icons, 8 others, 9.5ms\n",
            "image 32/125 /content/test_dataset/test_data/test_data/images/ak3.png: 608x1280 64 icons, 44 others, 8.1ms\n",
            "image 33/125 /content/test_dataset/test_data/test_data/images/akk4.png: 608x1280 28 icons, 17 others, 8.4ms\n",
            "image 34/125 /content/test_dataset/test_data/test_data/images/akk5.png: 672x1280 42 icons, 16 others, 9.2ms\n",
            "image 35/125 /content/test_dataset/test_data/test_data/images/akk6.png: 608x1280 23 icons, 4 others, 8.8ms\n",
            "image 36/125 /content/test_dataset/test_data/test_data/images/aksyd2.png: 672x1280 19 icons, 8 others, 8.6ms\n",
            "image 37/125 /content/test_dataset/test_data/test_data/images/aksyd4.png: 768x1280 59 icons, 14 others, 8.7ms\n",
            "image 38/125 /content/test_dataset/test_data/test_data/images/cgv.png: 704x1280 41 icons, 15 others, 8.9ms\n",
            "image 39/125 /content/test_dataset/test_data/test_data/images/image1 (1).png: 800x1280 31 icons, 19 others, 8.9ms\n",
            "image 40/125 /content/test_dataset/test_data/test_data/images/image1 (2).png: 864x1280 7 icons, 7 others, 9.0ms\n",
            "image 41/125 /content/test_dataset/test_data/test_data/images/image1.png: 672x1280 32 icons, 5 others, 8.8ms\n",
            "image 42/125 /content/test_dataset/test_data/test_data/images/image10 (1).png: 800x1280 56 icons, 7 others, 8.7ms\n",
            "image 43/125 /content/test_dataset/test_data/test_data/images/image10 (2).png: 768x1280 12 icons, 2 others, 8.8ms\n",
            "image 44/125 /content/test_dataset/test_data/test_data/images/image10.png: 672x1280 6 icons, 1 other, 9.0ms\n",
            "image 45/125 /content/test_dataset/test_data/test_data/images/image11 (1).png: 800x1280 39 icons, 4 others, 8.8ms\n",
            "image 46/125 /content/test_dataset/test_data/test_data/images/image11 (2).png: 768x1280 2 icons, 2 others, 8.9ms\n",
            "image 47/125 /content/test_dataset/test_data/test_data/images/image11.png: 640x1280 18 icons, 4 others, 9.1ms\n",
            "image 48/125 /content/test_dataset/test_data/test_data/images/image12 (1).png: 800x1280 60 icons, 9 others, 8.7ms\n",
            "image 49/125 /content/test_dataset/test_data/test_data/images/image12 (2).png: 768x1280 41 icons, 19 others, 8.8ms\n",
            "image 50/125 /content/test_dataset/test_data/test_data/images/image12.png: 640x1280 15 icons, 16 others, 8.8ms\n",
            "image 51/125 /content/test_dataset/test_data/test_data/images/image13 (1).png: 800x1280 91 icons, 8 others, 8.7ms\n",
            "image 52/125 /content/test_dataset/test_data/test_data/images/image13 (2).png: 736x1280 27 icons, 9 others, 8.8ms\n",
            "image 53/125 /content/test_dataset/test_data/test_data/images/image13.png: 640x1280 45 icons, 16 others, 8.9ms\n",
            "image 54/125 /content/test_dataset/test_data/test_data/images/image14(1).png: 640x1280 42 icons, 12 others, 11.5ms\n",
            "image 55/125 /content/test_dataset/test_data/test_data/images/image14.png: 800x1280 62 icons, 3 others, 8.8ms\n",
            "image 56/125 /content/test_dataset/test_data/test_data/images/image15.png: 640x1280 82 icons, 15 others, 8.8ms\n",
            "image 57/125 /content/test_dataset/test_data/test_data/images/image2 (1).png: 800x1280 50 icons, 2 others, 8.6ms\n",
            "image 58/125 /content/test_dataset/test_data/test_data/images/image2 (2).png: 768x1280 6 icons, 11 others, 8.8ms\n",
            "image 59/125 /content/test_dataset/test_data/test_data/images/image2.png: 640x1280 62 icons, 6 others, 8.8ms\n",
            "image 60/125 /content/test_dataset/test_data/test_data/images/image3 (1).png: 800x1280 71 icons, 28 others, 8.8ms\n",
            "image 61/125 /content/test_dataset/test_data/test_data/images/image3 (2).png: 768x1280 34 icons, 11 others, 10.0ms\n",
            "image 62/125 /content/test_dataset/test_data/test_data/images/image3.png: 672x1280 17 icons, 12 others, 9.2ms\n",
            "image 63/125 /content/test_dataset/test_data/test_data/images/image4 (1).png: 800x1280 66 icons, 1 other, 8.6ms\n",
            "image 64/125 /content/test_dataset/test_data/test_data/images/image4 (2).png: 1120x1280 9 icons, 1 other, 10.3ms\n",
            "image 65/125 /content/test_dataset/test_data/test_data/images/image4.png: 640x1280 61 icons, 12 others, 8.6ms\n",
            "image 66/125 /content/test_dataset/test_data/test_data/images/image5 (1).png: 800x1280 84 icons, 1 other, 8.7ms\n",
            "image 67/125 /content/test_dataset/test_data/test_data/images/image5 (2).png: 768x1280 15 icons, 8 others, 9.4ms\n",
            "image 68/125 /content/test_dataset/test_data/test_data/images/image5.png: 704x1280 46 icons, 2 others, 8.8ms\n",
            "image 69/125 /content/test_dataset/test_data/test_data/images/image6 (1).png: 800x1280 57 icons, 3 others, 8.7ms\n",
            "image 70/125 /content/test_dataset/test_data/test_data/images/image6 (2).png: 768x1280 29 icons, 12 others, 11.1ms\n",
            "image 71/125 /content/test_dataset/test_data/test_data/images/image6.png: 672x1280 10 icons, 7 others, 8.9ms\n",
            "image 72/125 /content/test_dataset/test_data/test_data/images/image7 (1).png: 800x1280 56 icons, 6 others, 8.8ms\n",
            "image 73/125 /content/test_dataset/test_data/test_data/images/image7 (2).png: 768x1280 13 icons, 3 others, 8.8ms\n",
            "image 74/125 /content/test_dataset/test_data/test_data/images/image7.png: 672x1280 20 icons, 7 others, 8.9ms\n",
            "image 75/125 /content/test_dataset/test_data/test_data/images/image8 (1).png: 800x1280 84 icons, 4 others, 8.6ms\n",
            "image 76/125 /content/test_dataset/test_data/test_data/images/image8 (2).png: 768x1280 16 icons, 4 others, 8.8ms\n",
            "image 77/125 /content/test_dataset/test_data/test_data/images/image8.png: 640x1280 62 icons, 12 others, 8.7ms\n",
            "image 78/125 /content/test_dataset/test_data/test_data/images/image9 (1).png: 800x1280 70 icons, 4 others, 9.3ms\n",
            "image 79/125 /content/test_dataset/test_data/test_data/images/image9 (2).png: 768x1280 34 icons, 7 others, 9.4ms\n",
            "image 80/125 /content/test_dataset/test_data/test_data/images/image9.png: 640x1280 18 icons, 6 others, 8.7ms\n",
            "image 81/125 /content/test_dataset/test_data/test_data/images/kt.png: 704x1280 38 icons, 9 others, 8.6ms\n",
            "image 82/125 /content/test_dataset/test_data/test_data/images/y050302.png: 704x1280 39 icons, 13 others, 7.9ms\n",
            "image 83/125 /content/test_dataset/test_data/test_data/images/y050502.png: 704x1280 17 icons, 18 others, 7.8ms\n",
            "image 84/125 /content/test_dataset/test_data/test_data/images/y050530.png: 704x1280 15 icons, 18 others, 7.9ms\n",
            "image 85/125 /content/test_dataset/test_data/test_data/images/y050549.png: 704x1280 14 icons, 14 others, 8.0ms\n",
            "image 86/125 /content/test_dataset/test_data/test_data/images/y050645.png: 640x1280 47 icons, 9.2ms\n",
            "image 87/125 /content/test_dataset/test_data/test_data/images/y154630.png: 704x1280 28 icons, 11 others, 10.2ms\n",
            "image 88/125 /content/test_dataset/test_data/test_data/images/y154706.png: 672x1280 17 icons, 6 others, 8.7ms\n",
            "image 89/125 /content/test_dataset/test_data/test_data/images/y154834.png: 704x1280 16 icons, 2 others, 8.6ms\n",
            "image 90/125 /content/test_dataset/test_data/test_data/images/y155251.png: 704x1280 31 icons, 29 others, 8.2ms\n",
            "image 91/125 /content/test_dataset/test_data/test_data/images/y155325.png: 672x1280 22 icons, 16 others, 9.3ms\n",
            "image 92/125 /content/test_dataset/test_data/test_data/images/y155407.png: 704x1280 29 icons, 8 others, 8.7ms\n",
            "image 93/125 /content/test_dataset/test_data/test_data/images/y155443.png: 704x1280 20 icons, 22 others, 8.1ms\n",
            "image 94/125 /content/test_dataset/test_data/test_data/images/y160130.png: 704x1280 35 icons, 13 others, 8.0ms\n",
            "image 95/125 /content/test_dataset/test_data/test_data/images/y160356.png: 704x1280 39 icons, 12 others, 8.0ms\n",
            "image 96/125 /content/test_dataset/test_data/test_data/images/z2.png: 640x1280 18 icons, 3 others, 8.7ms\n",
            "image 97/125 /content/test_dataset/test_data/test_data/images/z3.png: 640x1280 67 icons, 20 others, 8.1ms\n",
            "image 98/125 /content/test_dataset/test_data/test_data/images/z4.png: 640x1280 16 icons, 2 others, 8.1ms\n",
            "image 99/125 /content/test_dataset/test_data/test_data/images/당근.png: 704x1280 13 icons, 7 others, 8.5ms\n",
            "image 100/125 /content/test_dataset/test_data/test_data/images/도쿄디즈니랜드.png: 704x1280 59 icons, 7 others, 8.0ms\n",
            "image 101/125 /content/test_dataset/test_data/test_data/images/링크드인.png: 704x1280 25 icons, 12 others, 7.9ms\n",
            "image 102/125 /content/test_dataset/test_data/test_data/images/메가박스.png: 704x1280 51 icons, 20 others, 7.8ms\n",
            "image 103/125 /content/test_dataset/test_data/test_data/images/소니-아이보.png: 704x1280 17 icons, 5 others, 8.0ms\n",
            "image 104/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 195700.png: 704x1280 66 icons, 5 others, 8.6ms\n",
            "image 105/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 195717.png: 704x1280 42 icons, 10 others, 8.1ms\n",
            "image 106/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200021.png: 704x1280 47 icons, 20 others, 7.8ms\n",
            "image 107/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200225.png: 704x1280 41 icons, 5 others, 7.8ms\n",
            "image 108/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200547.png: 704x1280 51 icons, 5 others, 8.0ms\n",
            "image 109/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200651.png: 704x1280 35 icons, 7 others, 7.9ms\n",
            "image 110/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200750.png: 704x1280 42 icons, 11 others, 7.8ms\n",
            "image 111/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200847.png: 704x1280 52 icons, 11 others, 7.8ms\n",
            "image 112/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 200909.png: 704x1280 41 icons, 16 others, 7.9ms\n",
            "image 113/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 201100.png: 704x1280 43 icons, 7 others, 7.9ms\n",
            "image 114/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 201121.png: 704x1280 35 icons, 2 others, 7.8ms\n",
            "image 115/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 201304.png: 704x1280 46 icons, 4 others, 7.8ms\n",
            "image 116/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 201434.png: 704x1280 41 icons, 11 others, 7.9ms\n",
            "image 117/125 /content/test_dataset/test_data/test_data/images/스크린샷 2025-06-08 203539.png: 704x1280 43 icons, 8 others, 7.8ms\n",
            "image 118/125 /content/test_dataset/test_data/test_data/images/실시간지하철노선도.png: 704x1280 121 icons, 92 others, 8.1ms\n",
            "image 119/125 /content/test_dataset/test_data/test_data/images/안경-라운즈.png: 704x1280 28 icons, 9 others, 7.8ms\n",
            "image 120/125 /content/test_dataset/test_data/test_data/images/에버랜드.png: 704x1280 32 icons, 3 others, 7.8ms\n",
            "image 121/125 /content/test_dataset/test_data/test_data/images/울프람알파.png: 704x1280 33 icons, 4 others, 8.0ms\n",
            "image 122/125 /content/test_dataset/test_data/test_data/images/유튜브.png: 704x1280 23 icons, 2 others, 7.9ms\n",
            "image 123/125 /content/test_dataset/test_data/test_data/images/이케아.png: 704x1280 35 icons, 11 others, 7.9ms\n",
            "image 124/125 /content/test_dataset/test_data/test_data/images/정부24.png: 704x1280 25 icons, 20 others, 7.7ms\n",
            "image 125/125 /content/test_dataset/test_data/test_data/images/코드잇.png: 704x1280 25 icons, 11 others, 7.9ms\n",
            "Speed: 7.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 704, 1280)\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "125 labels saved to runs/detect/val4/labels\n",
            "\n",
            "📊 [ICON ONLY] 성능 측정 결과:\n",
            "metrics/precision(B)     : 0.3566\n",
            "metrics/recall(B)        : 0.3640\n",
            "metrics/mAP50(B)         : 0.2627\n",
            "metrics/mAP50-95(B)      : 0.0904\n",
            "fitness                  : 0.1076\n"
          ]
        }
      ]
    }
  ]
}